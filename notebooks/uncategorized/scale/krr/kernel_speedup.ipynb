{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RBF Calculation Speed-Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from krr import KRR, rbf_derivative\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics.pairwise import rbf_kernel\n",
    "\n",
    "import cProfile\n",
    "from rbf_derivative_cy import rbf_derivative as rbf_derivative_cy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/eman/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "random_state = 123\n",
    "num_points = 1000\n",
    "x_data = np.arange(0, num_points)\n",
    "y_data = np.sin(x_data)\n",
    "\n",
    "# split into training and testing\n",
    "train_prnt = 0.7\n",
    "x_train, x_test, y_train, y_test = \\\n",
    "    train_test_split(x_data, y_data,\n",
    "                     train_size=train_prnt,\n",
    "                     random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# make a new axis D [N x D]\n",
    "x_train, x_test = x_train[:, np.newaxis], x_test[:, np.newaxis]\n",
    "y_train, y_test = y_train[:, np.newaxis], y_test[:, np.newaxis]\n",
    "\n",
    "# remove the mean from y training\n",
    "y_train = y_train - np.mean(y_train)\n",
    "\n",
    "param_grid = {\"alpha\": [1e0, 1e-1, 1e-2, 1e-3],\n",
    "              \"gamma\": np.logspace(-2, 2, 5)}\n",
    "\n",
    "# initialize the kernel ridge regression model\n",
    "KRR_model = GridSearchCV(KernelRidge(kernel='rbf'), \n",
    "                         cv=5, param_grid=param_grid)\n",
    "\n",
    "# fit model to data\n",
    "KRR_model.fit(x_train, y_train)\n",
    "\n",
    "# predict using the krr model\n",
    "y_pred = KRR_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RBF Derivative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rbf_derivative(x_train, x_function, weights, kernel_mat,\n",
    "                   n_derivative=1, gamma=1.0):\n",
    "    \"\"\"This function calculates the rbf derivative\n",
    "    Parameters\n",
    "    ----------\n",
    "    x_train : array, [N x D]\n",
    "        The training data used to find the kernel model.\n",
    "\n",
    "    x_function  : array, [M x D]\n",
    "        The test points (or vector) to use.\n",
    "\n",
    "    weights   : array, [N x D]\n",
    "        The weights found from the kernel model\n",
    "            y = K * weights\n",
    "\n",
    "    kernel_mat: array, [N x M], default: None\n",
    "        The rbf kernel matrix with the similarities between the test\n",
    "        points and the training points.\n",
    "\n",
    "    n_derivative : int, (default = 1) {1, 2}\n",
    "        chooses which nth derivative to calculate\n",
    "\n",
    "    gamma : float, default: None\n",
    "        the parameter for the rbf_kernel matrix function\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "\n",
    "    derivative : array, [M x D]\n",
    "        returns the derivative with respect to training points used in\n",
    "        the kernel model and the test points.\n",
    "\n",
    "    Information\n",
    "    -----------\n",
    "    Author: Juan Emmanuel Johnson\n",
    "    Email : jej2744@rit.edu\n",
    "            juan.johnson@uv.es\n",
    "    \"\"\"\n",
    "\n",
    "    # initialize rbf kernel\n",
    "    derivative = np.zeros(np.shape(x_function))\n",
    "\n",
    "    # consolidate the parameters\n",
    "    theta = 2 * gamma\n",
    "\n",
    "    # 1st derivative\n",
    "    if n_derivative == 1:\n",
    "\n",
    "        # loop through dimensions\n",
    "        for dim in np.arange(0, np.shape(x_function)[1]):\n",
    "\n",
    "            # loop through the number of test points\n",
    "            for iTest in np.arange(0, np.shape(x_function)[0]):\n",
    "\n",
    "                # loop through the number of test points\n",
    "                for iTrain in np.arange(0, np.shape(x_train)[0]):\n",
    "\n",
    "                    # calculate the derivative for the test points\n",
    "                    derivative[iTest, dim] += theta * weights[iTrain] * \\\n",
    "                                              (x_train[iTrain, dim] -\n",
    "                                               x_function[iTest, dim]) * \\\n",
    "                                              kernel_mat[iTrain, iTest]\n",
    "\n",
    "    # 2nd derivative\n",
    "    elif n_derivative == 2:\n",
    "\n",
    "        # loop through dimensions\n",
    "        for dim in np.arange(0, np.shape(x_function)[1]):\n",
    "\n",
    "            # loop through the number of test points\n",
    "            for iTest in np.arange(0, np.shape(x_function)[0]):\n",
    "\n",
    "                # loop through the number of test points\n",
    "                for iTrain in np.arange(0, np.shape(x_train)[0]):\n",
    "                    derivative[iTest, dim] += weights[iTrain] * \\\n",
    "                                              (theta ** 2 *\n",
    "                                               (x_train[iTrain, dim] - x_function[iTest, dim]) ** 2\n",
    "                                               - theta) * \\\n",
    "                                              kernel_mat[iTrain, iTest]\n",
    "\n",
    "    return derivative\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# extract necessary parameters\n",
    "gamma = KRR_model.best_params_['gamma']\n",
    "weights = KRR_model.best_estimator_.dual_coef_\n",
    "kernel = rbf_kernel(x_train, gamma=gamma)\n",
    "n_derivative = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "derivative = rbf_derivative(x_train, x_test, weights=weights, kernel_mat=kernel, n_derivative=n_derivative, gamma=gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "derivative_cy = rbf_derivative_cy(np.float64(x_train), \n",
    "                                  np.float64(x_test), \n",
    "                                  weights=weights.squeeze(), \n",
    "                                  kernel_mat=kernel, \n",
    "                                  n_derivative=n_derivative, \n",
    "                                  gamma=gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "float64\n",
      "float64\n"
     ]
    }
   ],
   "source": [
    "print(np.array_equal(derivative, derivative_cy))\n",
    "print(derivative.dtype)\n",
    "print(derivative_cy.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Timing the Current Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.45 s ± 126 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "original_python = %timeit -o rbf_derivative(x_train, x_test, weights=weights, kernel_mat=kernel, n_derivative=n_derivative, gamma=gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    }
   ],
   "source": [
    "#cProfile.run('rbf_derivative(x_train, x_test, weights=weights, kernel_mat=kernel, n_derivative=n_derivative, gamma=gamma)')\n",
    "%prun rbf_derivative(x_train, x_test, weights=weights, kernel_mat=kernel, n_derivative=n_derivative, gamma=gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%lprun -f rbf_derivative rbf_derivative(x_train, x_test, weights=weights, kernel_mat=kernel, gamma=gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from numba import double\n",
    "from numba import jit, autojit, njit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rbf_derivative_numba = jit()(rbf_derivative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# compile it the first time\n",
    "derivative_numba = rbf_derivative_numba(x_train, x_test, kernel_mat=kernel, weights=weights, gamma=gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numba w/ Jit:\n",
      "1.36 s ± 13.9 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "print('Numba w/ Jit:')\n",
    "jit_speedup = %timeit -o rbf_derivative_numba(x_train, x_test, kernel_mat=kernel, weights=weights, gamma=gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.013040010240821\n"
     ]
    }
   ],
   "source": [
    "print(original_python.best / jit_speedup.best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext cython"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With GIL Lock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<!DOCTYPE html>\n",
       "<!-- Generated by Cython 0.26.1 -->\n",
       "<html>\n",
       "<head>\n",
       "    <meta http-equiv=\"Content-Type\" content=\"text/html; charset=utf-8\" />\n",
       "    <title>Cython: _cython_magic_068b7d05edfe1c28296fa0d160e3f997.pyx</title>\n",
       "    <style type=\"text/css\">\n",
       "    \n",
       "body.cython { font-family: courier; font-size: 12; }\n",
       "\n",
       ".cython.tag  {  }\n",
       ".cython.line { margin: 0em }\n",
       ".cython.code { font-size: 9; color: #444444; display: none; margin: 0px 0px 0px 8px; border-left: 8px none; }\n",
       "\n",
       ".cython.line .run { background-color: #B0FFB0; }\n",
       ".cython.line .mis { background-color: #FFB0B0; }\n",
       ".cython.code.run  { border-left: 8px solid #B0FFB0; }\n",
       ".cython.code.mis  { border-left: 8px solid #FFB0B0; }\n",
       "\n",
       ".cython.code .py_c_api  { color: red; }\n",
       ".cython.code .py_macro_api  { color: #FF7000; }\n",
       ".cython.code .pyx_c_api  { color: #FF3000; }\n",
       ".cython.code .pyx_macro_api  { color: #FF7000; }\n",
       ".cython.code .refnanny  { color: #FFA000; }\n",
       ".cython.code .trace  { color: #FFA000; }\n",
       ".cython.code .error_goto  { color: #FFA000; }\n",
       "\n",
       ".cython.code .coerce  { color: #008000; border: 1px dotted #008000 }\n",
       ".cython.code .py_attr { color: #FF0000; font-weight: bold; }\n",
       ".cython.code .c_attr  { color: #0000FF; }\n",
       ".cython.code .py_call { color: #FF0000; font-weight: bold; }\n",
       ".cython.code .c_call  { color: #0000FF; }\n",
       "\n",
       ".cython.score-0 {background-color: #FFFFff;}\n",
       ".cython.score-1 {background-color: #FFFFe7;}\n",
       ".cython.score-2 {background-color: #FFFFd4;}\n",
       ".cython.score-3 {background-color: #FFFFc4;}\n",
       ".cython.score-4 {background-color: #FFFFb6;}\n",
       ".cython.score-5 {background-color: #FFFFaa;}\n",
       ".cython.score-6 {background-color: #FFFF9f;}\n",
       ".cython.score-7 {background-color: #FFFF96;}\n",
       ".cython.score-8 {background-color: #FFFF8d;}\n",
       ".cython.score-9 {background-color: #FFFF86;}\n",
       ".cython.score-10 {background-color: #FFFF7f;}\n",
       ".cython.score-11 {background-color: #FFFF79;}\n",
       ".cython.score-12 {background-color: #FFFF73;}\n",
       ".cython.score-13 {background-color: #FFFF6e;}\n",
       ".cython.score-14 {background-color: #FFFF6a;}\n",
       ".cython.score-15 {background-color: #FFFF66;}\n",
       ".cython.score-16 {background-color: #FFFF62;}\n",
       ".cython.score-17 {background-color: #FFFF5e;}\n",
       ".cython.score-18 {background-color: #FFFF5b;}\n",
       ".cython.score-19 {background-color: #FFFF57;}\n",
       ".cython.score-20 {background-color: #FFFF55;}\n",
       ".cython.score-21 {background-color: #FFFF52;}\n",
       ".cython.score-22 {background-color: #FFFF4f;}\n",
       ".cython.score-23 {background-color: #FFFF4d;}\n",
       ".cython.score-24 {background-color: #FFFF4b;}\n",
       ".cython.score-25 {background-color: #FFFF48;}\n",
       ".cython.score-26 {background-color: #FFFF46;}\n",
       ".cython.score-27 {background-color: #FFFF44;}\n",
       ".cython.score-28 {background-color: #FFFF43;}\n",
       ".cython.score-29 {background-color: #FFFF41;}\n",
       ".cython.score-30 {background-color: #FFFF3f;}\n",
       ".cython.score-31 {background-color: #FFFF3e;}\n",
       ".cython.score-32 {background-color: #FFFF3c;}\n",
       ".cython.score-33 {background-color: #FFFF3b;}\n",
       ".cython.score-34 {background-color: #FFFF39;}\n",
       ".cython.score-35 {background-color: #FFFF38;}\n",
       ".cython.score-36 {background-color: #FFFF37;}\n",
       ".cython.score-37 {background-color: #FFFF36;}\n",
       ".cython.score-38 {background-color: #FFFF35;}\n",
       ".cython.score-39 {background-color: #FFFF34;}\n",
       ".cython.score-40 {background-color: #FFFF33;}\n",
       ".cython.score-41 {background-color: #FFFF32;}\n",
       ".cython.score-42 {background-color: #FFFF31;}\n",
       ".cython.score-43 {background-color: #FFFF30;}\n",
       ".cython.score-44 {background-color: #FFFF2f;}\n",
       ".cython.score-45 {background-color: #FFFF2e;}\n",
       ".cython.score-46 {background-color: #FFFF2d;}\n",
       ".cython.score-47 {background-color: #FFFF2c;}\n",
       ".cython.score-48 {background-color: #FFFF2b;}\n",
       ".cython.score-49 {background-color: #FFFF2b;}\n",
       ".cython.score-50 {background-color: #FFFF2a;}\n",
       ".cython.score-51 {background-color: #FFFF29;}\n",
       ".cython.score-52 {background-color: #FFFF29;}\n",
       ".cython.score-53 {background-color: #FFFF28;}\n",
       ".cython.score-54 {background-color: #FFFF27;}\n",
       ".cython.score-55 {background-color: #FFFF27;}\n",
       ".cython.score-56 {background-color: #FFFF26;}\n",
       ".cython.score-57 {background-color: #FFFF26;}\n",
       ".cython.score-58 {background-color: #FFFF25;}\n",
       ".cython.score-59 {background-color: #FFFF24;}\n",
       ".cython.score-60 {background-color: #FFFF24;}\n",
       ".cython.score-61 {background-color: #FFFF23;}\n",
       ".cython.score-62 {background-color: #FFFF23;}\n",
       ".cython.score-63 {background-color: #FFFF22;}\n",
       ".cython.score-64 {background-color: #FFFF22;}\n",
       ".cython.score-65 {background-color: #FFFF22;}\n",
       ".cython.score-66 {background-color: #FFFF21;}\n",
       ".cython.score-67 {background-color: #FFFF21;}\n",
       ".cython.score-68 {background-color: #FFFF20;}\n",
       ".cython.score-69 {background-color: #FFFF20;}\n",
       ".cython.score-70 {background-color: #FFFF1f;}\n",
       ".cython.score-71 {background-color: #FFFF1f;}\n",
       ".cython.score-72 {background-color: #FFFF1f;}\n",
       ".cython.score-73 {background-color: #FFFF1e;}\n",
       ".cython.score-74 {background-color: #FFFF1e;}\n",
       ".cython.score-75 {background-color: #FFFF1e;}\n",
       ".cython.score-76 {background-color: #FFFF1d;}\n",
       ".cython.score-77 {background-color: #FFFF1d;}\n",
       ".cython.score-78 {background-color: #FFFF1c;}\n",
       ".cython.score-79 {background-color: #FFFF1c;}\n",
       ".cython.score-80 {background-color: #FFFF1c;}\n",
       ".cython.score-81 {background-color: #FFFF1c;}\n",
       ".cython.score-82 {background-color: #FFFF1b;}\n",
       ".cython.score-83 {background-color: #FFFF1b;}\n",
       ".cython.score-84 {background-color: #FFFF1b;}\n",
       ".cython.score-85 {background-color: #FFFF1a;}\n",
       ".cython.score-86 {background-color: #FFFF1a;}\n",
       ".cython.score-87 {background-color: #FFFF1a;}\n",
       ".cython.score-88 {background-color: #FFFF1a;}\n",
       ".cython.score-89 {background-color: #FFFF19;}\n",
       ".cython.score-90 {background-color: #FFFF19;}\n",
       ".cython.score-91 {background-color: #FFFF19;}\n",
       ".cython.score-92 {background-color: #FFFF19;}\n",
       ".cython.score-93 {background-color: #FFFF18;}\n",
       ".cython.score-94 {background-color: #FFFF18;}\n",
       ".cython.score-95 {background-color: #FFFF18;}\n",
       ".cython.score-96 {background-color: #FFFF18;}\n",
       ".cython.score-97 {background-color: #FFFF17;}\n",
       ".cython.score-98 {background-color: #FFFF17;}\n",
       ".cython.score-99 {background-color: #FFFF17;}\n",
       ".cython.score-100 {background-color: #FFFF17;}\n",
       ".cython.score-101 {background-color: #FFFF16;}\n",
       ".cython.score-102 {background-color: #FFFF16;}\n",
       ".cython.score-103 {background-color: #FFFF16;}\n",
       ".cython.score-104 {background-color: #FFFF16;}\n",
       ".cython.score-105 {background-color: #FFFF16;}\n",
       ".cython.score-106 {background-color: #FFFF15;}\n",
       ".cython.score-107 {background-color: #FFFF15;}\n",
       ".cython.score-108 {background-color: #FFFF15;}\n",
       ".cython.score-109 {background-color: #FFFF15;}\n",
       ".cython.score-110 {background-color: #FFFF15;}\n",
       ".cython.score-111 {background-color: #FFFF15;}\n",
       ".cython.score-112 {background-color: #FFFF14;}\n",
       ".cython.score-113 {background-color: #FFFF14;}\n",
       ".cython.score-114 {background-color: #FFFF14;}\n",
       ".cython.score-115 {background-color: #FFFF14;}\n",
       ".cython.score-116 {background-color: #FFFF14;}\n",
       ".cython.score-117 {background-color: #FFFF14;}\n",
       ".cython.score-118 {background-color: #FFFF13;}\n",
       ".cython.score-119 {background-color: #FFFF13;}\n",
       ".cython.score-120 {background-color: #FFFF13;}\n",
       ".cython.score-121 {background-color: #FFFF13;}\n",
       ".cython.score-122 {background-color: #FFFF13;}\n",
       ".cython.score-123 {background-color: #FFFF13;}\n",
       ".cython.score-124 {background-color: #FFFF13;}\n",
       ".cython.score-125 {background-color: #FFFF12;}\n",
       ".cython.score-126 {background-color: #FFFF12;}\n",
       ".cython.score-127 {background-color: #FFFF12;}\n",
       ".cython.score-128 {background-color: #FFFF12;}\n",
       ".cython.score-129 {background-color: #FFFF12;}\n",
       ".cython.score-130 {background-color: #FFFF12;}\n",
       ".cython.score-131 {background-color: #FFFF12;}\n",
       ".cython.score-132 {background-color: #FFFF11;}\n",
       ".cython.score-133 {background-color: #FFFF11;}\n",
       ".cython.score-134 {background-color: #FFFF11;}\n",
       ".cython.score-135 {background-color: #FFFF11;}\n",
       ".cython.score-136 {background-color: #FFFF11;}\n",
       ".cython.score-137 {background-color: #FFFF11;}\n",
       ".cython.score-138 {background-color: #FFFF11;}\n",
       ".cython.score-139 {background-color: #FFFF11;}\n",
       ".cython.score-140 {background-color: #FFFF11;}\n",
       ".cython.score-141 {background-color: #FFFF10;}\n",
       ".cython.score-142 {background-color: #FFFF10;}\n",
       ".cython.score-143 {background-color: #FFFF10;}\n",
       ".cython.score-144 {background-color: #FFFF10;}\n",
       ".cython.score-145 {background-color: #FFFF10;}\n",
       ".cython.score-146 {background-color: #FFFF10;}\n",
       ".cython.score-147 {background-color: #FFFF10;}\n",
       ".cython.score-148 {background-color: #FFFF10;}\n",
       ".cython.score-149 {background-color: #FFFF10;}\n",
       ".cython.score-150 {background-color: #FFFF0f;}\n",
       ".cython.score-151 {background-color: #FFFF0f;}\n",
       ".cython.score-152 {background-color: #FFFF0f;}\n",
       ".cython.score-153 {background-color: #FFFF0f;}\n",
       ".cython.score-154 {background-color: #FFFF0f;}\n",
       ".cython.score-155 {background-color: #FFFF0f;}\n",
       ".cython.score-156 {background-color: #FFFF0f;}\n",
       ".cython.score-157 {background-color: #FFFF0f;}\n",
       ".cython.score-158 {background-color: #FFFF0f;}\n",
       ".cython.score-159 {background-color: #FFFF0f;}\n",
       ".cython.score-160 {background-color: #FFFF0f;}\n",
       ".cython.score-161 {background-color: #FFFF0e;}\n",
       ".cython.score-162 {background-color: #FFFF0e;}\n",
       ".cython.score-163 {background-color: #FFFF0e;}\n",
       ".cython.score-164 {background-color: #FFFF0e;}\n",
       ".cython.score-165 {background-color: #FFFF0e;}\n",
       ".cython.score-166 {background-color: #FFFF0e;}\n",
       ".cython.score-167 {background-color: #FFFF0e;}\n",
       ".cython.score-168 {background-color: #FFFF0e;}\n",
       ".cython.score-169 {background-color: #FFFF0e;}\n",
       ".cython.score-170 {background-color: #FFFF0e;}\n",
       ".cython.score-171 {background-color: #FFFF0e;}\n",
       ".cython.score-172 {background-color: #FFFF0e;}\n",
       ".cython.score-173 {background-color: #FFFF0d;}\n",
       ".cython.score-174 {background-color: #FFFF0d;}\n",
       ".cython.score-175 {background-color: #FFFF0d;}\n",
       ".cython.score-176 {background-color: #FFFF0d;}\n",
       ".cython.score-177 {background-color: #FFFF0d;}\n",
       ".cython.score-178 {background-color: #FFFF0d;}\n",
       ".cython.score-179 {background-color: #FFFF0d;}\n",
       ".cython.score-180 {background-color: #FFFF0d;}\n",
       ".cython.score-181 {background-color: #FFFF0d;}\n",
       ".cython.score-182 {background-color: #FFFF0d;}\n",
       ".cython.score-183 {background-color: #FFFF0d;}\n",
       ".cython.score-184 {background-color: #FFFF0d;}\n",
       ".cython.score-185 {background-color: #FFFF0d;}\n",
       ".cython.score-186 {background-color: #FFFF0d;}\n",
       ".cython.score-187 {background-color: #FFFF0c;}\n",
       ".cython.score-188 {background-color: #FFFF0c;}\n",
       ".cython.score-189 {background-color: #FFFF0c;}\n",
       ".cython.score-190 {background-color: #FFFF0c;}\n",
       ".cython.score-191 {background-color: #FFFF0c;}\n",
       ".cython.score-192 {background-color: #FFFF0c;}\n",
       ".cython.score-193 {background-color: #FFFF0c;}\n",
       ".cython.score-194 {background-color: #FFFF0c;}\n",
       ".cython.score-195 {background-color: #FFFF0c;}\n",
       ".cython.score-196 {background-color: #FFFF0c;}\n",
       ".cython.score-197 {background-color: #FFFF0c;}\n",
       ".cython.score-198 {background-color: #FFFF0c;}\n",
       ".cython.score-199 {background-color: #FFFF0c;}\n",
       ".cython.score-200 {background-color: #FFFF0c;}\n",
       ".cython.score-201 {background-color: #FFFF0c;}\n",
       ".cython.score-202 {background-color: #FFFF0c;}\n",
       ".cython.score-203 {background-color: #FFFF0b;}\n",
       ".cython.score-204 {background-color: #FFFF0b;}\n",
       ".cython.score-205 {background-color: #FFFF0b;}\n",
       ".cython.score-206 {background-color: #FFFF0b;}\n",
       ".cython.score-207 {background-color: #FFFF0b;}\n",
       ".cython.score-208 {background-color: #FFFF0b;}\n",
       ".cython.score-209 {background-color: #FFFF0b;}\n",
       ".cython.score-210 {background-color: #FFFF0b;}\n",
       ".cython.score-211 {background-color: #FFFF0b;}\n",
       ".cython.score-212 {background-color: #FFFF0b;}\n",
       ".cython.score-213 {background-color: #FFFF0b;}\n",
       ".cython.score-214 {background-color: #FFFF0b;}\n",
       ".cython.score-215 {background-color: #FFFF0b;}\n",
       ".cython.score-216 {background-color: #FFFF0b;}\n",
       ".cython.score-217 {background-color: #FFFF0b;}\n",
       ".cython.score-218 {background-color: #FFFF0b;}\n",
       ".cython.score-219 {background-color: #FFFF0b;}\n",
       ".cython.score-220 {background-color: #FFFF0b;}\n",
       ".cython.score-221 {background-color: #FFFF0b;}\n",
       ".cython.score-222 {background-color: #FFFF0a;}\n",
       ".cython.score-223 {background-color: #FFFF0a;}\n",
       ".cython.score-224 {background-color: #FFFF0a;}\n",
       ".cython.score-225 {background-color: #FFFF0a;}\n",
       ".cython.score-226 {background-color: #FFFF0a;}\n",
       ".cython.score-227 {background-color: #FFFF0a;}\n",
       ".cython.score-228 {background-color: #FFFF0a;}\n",
       ".cython.score-229 {background-color: #FFFF0a;}\n",
       ".cython.score-230 {background-color: #FFFF0a;}\n",
       ".cython.score-231 {background-color: #FFFF0a;}\n",
       ".cython.score-232 {background-color: #FFFF0a;}\n",
       ".cython.score-233 {background-color: #FFFF0a;}\n",
       ".cython.score-234 {background-color: #FFFF0a;}\n",
       ".cython.score-235 {background-color: #FFFF0a;}\n",
       ".cython.score-236 {background-color: #FFFF0a;}\n",
       ".cython.score-237 {background-color: #FFFF0a;}\n",
       ".cython.score-238 {background-color: #FFFF0a;}\n",
       ".cython.score-239 {background-color: #FFFF0a;}\n",
       ".cython.score-240 {background-color: #FFFF0a;}\n",
       ".cython.score-241 {background-color: #FFFF0a;}\n",
       ".cython.score-242 {background-color: #FFFF0a;}\n",
       ".cython.score-243 {background-color: #FFFF0a;}\n",
       ".cython.score-244 {background-color: #FFFF0a;}\n",
       ".cython.score-245 {background-color: #FFFF0a;}\n",
       ".cython.score-246 {background-color: #FFFF09;}\n",
       ".cython.score-247 {background-color: #FFFF09;}\n",
       ".cython.score-248 {background-color: #FFFF09;}\n",
       ".cython.score-249 {background-color: #FFFF09;}\n",
       ".cython.score-250 {background-color: #FFFF09;}\n",
       ".cython.score-251 {background-color: #FFFF09;}\n",
       ".cython.score-252 {background-color: #FFFF09;}\n",
       ".cython.score-253 {background-color: #FFFF09;}\n",
       ".cython.score-254 {background-color: #FFFF09;}\n",
       ".cython .hll { background-color: #ffffcc }\n",
       ".cython  { background: #f8f8f8; }\n",
       ".cython .c { color: #408080; font-style: italic } /* Comment */\n",
       ".cython .err { border: 1px solid #FF0000 } /* Error */\n",
       ".cython .k { color: #008000; font-weight: bold } /* Keyword */\n",
       ".cython .o { color: #666666 } /* Operator */\n",
       ".cython .ch { color: #408080; font-style: italic } /* Comment.Hashbang */\n",
       ".cython .cm { color: #408080; font-style: italic } /* Comment.Multiline */\n",
       ".cython .cp { color: #BC7A00 } /* Comment.Preproc */\n",
       ".cython .cpf { color: #408080; font-style: italic } /* Comment.PreprocFile */\n",
       ".cython .c1 { color: #408080; font-style: italic } /* Comment.Single */\n",
       ".cython .cs { color: #408080; font-style: italic } /* Comment.Special */\n",
       ".cython .gd { color: #A00000 } /* Generic.Deleted */\n",
       ".cython .ge { font-style: italic } /* Generic.Emph */\n",
       ".cython .gr { color: #FF0000 } /* Generic.Error */\n",
       ".cython .gh { color: #000080; font-weight: bold } /* Generic.Heading */\n",
       ".cython .gi { color: #00A000 } /* Generic.Inserted */\n",
       ".cython .go { color: #888888 } /* Generic.Output */\n",
       ".cython .gp { color: #000080; font-weight: bold } /* Generic.Prompt */\n",
       ".cython .gs { font-weight: bold } /* Generic.Strong */\n",
       ".cython .gu { color: #800080; font-weight: bold } /* Generic.Subheading */\n",
       ".cython .gt { color: #0044DD } /* Generic.Traceback */\n",
       ".cython .kc { color: #008000; font-weight: bold } /* Keyword.Constant */\n",
       ".cython .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */\n",
       ".cython .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */\n",
       ".cython .kp { color: #008000 } /* Keyword.Pseudo */\n",
       ".cython .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */\n",
       ".cython .kt { color: #B00040 } /* Keyword.Type */\n",
       ".cython .m { color: #666666 } /* Literal.Number */\n",
       ".cython .s { color: #BA2121 } /* Literal.String */\n",
       ".cython .na { color: #7D9029 } /* Name.Attribute */\n",
       ".cython .nb { color: #008000 } /* Name.Builtin */\n",
       ".cython .nc { color: #0000FF; font-weight: bold } /* Name.Class */\n",
       ".cython .no { color: #880000 } /* Name.Constant */\n",
       ".cython .nd { color: #AA22FF } /* Name.Decorator */\n",
       ".cython .ni { color: #999999; font-weight: bold } /* Name.Entity */\n",
       ".cython .ne { color: #D2413A; font-weight: bold } /* Name.Exception */\n",
       ".cython .nf { color: #0000FF } /* Name.Function */\n",
       ".cython .nl { color: #A0A000 } /* Name.Label */\n",
       ".cython .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */\n",
       ".cython .nt { color: #008000; font-weight: bold } /* Name.Tag */\n",
       ".cython .nv { color: #19177C } /* Name.Variable */\n",
       ".cython .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */\n",
       ".cython .w { color: #bbbbbb } /* Text.Whitespace */\n",
       ".cython .mb { color: #666666 } /* Literal.Number.Bin */\n",
       ".cython .mf { color: #666666 } /* Literal.Number.Float */\n",
       ".cython .mh { color: #666666 } /* Literal.Number.Hex */\n",
       ".cython .mi { color: #666666 } /* Literal.Number.Integer */\n",
       ".cython .mo { color: #666666 } /* Literal.Number.Oct */\n",
       ".cython .sa { color: #BA2121 } /* Literal.String.Affix */\n",
       ".cython .sb { color: #BA2121 } /* Literal.String.Backtick */\n",
       ".cython .sc { color: #BA2121 } /* Literal.String.Char */\n",
       ".cython .dl { color: #BA2121 } /* Literal.String.Delimiter */\n",
       ".cython .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */\n",
       ".cython .s2 { color: #BA2121 } /* Literal.String.Double */\n",
       ".cython .se { color: #BB6622; font-weight: bold } /* Literal.String.Escape */\n",
       ".cython .sh { color: #BA2121 } /* Literal.String.Heredoc */\n",
       ".cython .si { color: #BB6688; font-weight: bold } /* Literal.String.Interpol */\n",
       ".cython .sx { color: #008000 } /* Literal.String.Other */\n",
       ".cython .sr { color: #BB6688 } /* Literal.String.Regex */\n",
       ".cython .s1 { color: #BA2121 } /* Literal.String.Single */\n",
       ".cython .ss { color: #19177C } /* Literal.String.Symbol */\n",
       ".cython .bp { color: #008000 } /* Name.Builtin.Pseudo */\n",
       ".cython .fm { color: #0000FF } /* Name.Function.Magic */\n",
       ".cython .vc { color: #19177C } /* Name.Variable.Class */\n",
       ".cython .vg { color: #19177C } /* Name.Variable.Global */\n",
       ".cython .vi { color: #19177C } /* Name.Variable.Instance */\n",
       ".cython .vm { color: #19177C } /* Name.Variable.Magic */\n",
       ".cython .il { color: #666666 } /* Literal.Number.Integer.Long */\n",
       "    </style>\n",
       "    <script>\n",
       "    function toggleDiv(id) {\n",
       "        theDiv = id.nextElementSibling\n",
       "        if (theDiv.style.display != 'block') theDiv.style.display = 'block';\n",
       "        else theDiv.style.display = 'none';\n",
       "    }\n",
       "    </script>\n",
       "</head>\n",
       "<body class=\"cython\">\n",
       "<p><span style=\"border-bottom: solid 1px grey;\">Generated by Cython 0.26.1</span></p>\n",
       "<p>\n",
       "    <span style=\"background-color: #FFFF00\">Yellow lines</span> hint at Python interaction.<br />\n",
       "    Click on a line that starts with a \"<code>+</code>\" to see the C code that Cython generated for it.\n",
       "</p>\n",
       "<div class=\"cython\"><pre class=\"cython line score-0\">&#xA0;<span class=\"\">001</span>: </pre>\n",
       "<pre class=\"cython line score-11\" onclick='toggleDiv(this)'>+<span class=\"\">002</span>: <span class=\"k\">cimport</span> <span class=\"nn\">cython</span></pre>\n",
       "<pre class='cython code score-11 '>  __pyx_t_1 = <span class='py_c_api'>PyDict_New</span>();<span class='error_goto'> if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 2, __pyx_L1_error)</span>\n",
       "  <span class='refnanny'>__Pyx_GOTREF</span>(__pyx_t_1);\n",
       "  if (<span class='py_c_api'>PyDict_SetItem</span>(__pyx_d, __pyx_n_s_test, __pyx_t_1) &lt; 0) <span class='error_goto'>__PYX_ERR(0, 2, __pyx_L1_error)</span>\n",
       "  <span class='pyx_macro_api'>__Pyx_DECREF</span>(__pyx_t_1); __pyx_t_1 = 0;\n",
       "</pre><pre class=\"cython line score-8\" onclick='toggleDiv(this)'>+<span class=\"\">003</span>: <span class=\"k\">import</span> <span class=\"nn\">numpy</span> <span class=\"k\">as</span> <span class=\"nn\">np</span></pre>\n",
       "<pre class='cython code score-8 '>  __pyx_t_1 = <span class='pyx_c_api'>__Pyx_Import</span>(__pyx_n_s_numpy, 0, 0);<span class='error_goto'> if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 3, __pyx_L1_error)</span>\n",
       "  <span class='refnanny'>__Pyx_GOTREF</span>(__pyx_t_1);\n",
       "  if (<span class='py_c_api'>PyDict_SetItem</span>(__pyx_d, __pyx_n_s_np, __pyx_t_1) &lt; 0) <span class='error_goto'>__PYX_ERR(0, 3, __pyx_L1_error)</span>\n",
       "  <span class='pyx_macro_api'>__Pyx_DECREF</span>(__pyx_t_1); __pyx_t_1 = 0;\n",
       "</pre><pre class=\"cython line score-0\">&#xA0;<span class=\"\">004</span>: <span class=\"k\">cimport</span> <span class=\"nn\">numpy</span> <span class=\"k\">as</span> <span class=\"nn\">np</span></pre>\n",
       "<pre class=\"cython line score-0\">&#xA0;<span class=\"\">005</span>: </pre>\n",
       "<pre class=\"cython line score-0\">&#xA0;<span class=\"\">006</span>: <span class=\"nd\">@cython</span><span class=\"o\">.</span><span class=\"n\">boundscheck</span><span class=\"p\">(</span><span class=\"bp\">False</span><span class=\"p\">)</span></pre>\n",
       "<pre class=\"cython line score-0\">&#xA0;<span class=\"\">007</span>: <span class=\"nd\">@cython</span><span class=\"o\">.</span><span class=\"n\">wraparound</span><span class=\"p\">(</span><span class=\"bp\">False</span><span class=\"p\">)</span></pre>\n",
       "<pre class=\"cython line score-103\" onclick='toggleDiv(this)'>+<span class=\"\">008</span>: <span class=\"k\">def</span> <span class=\"nf\">rbf_derivative_cython</span><span class=\"p\">(</span><span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">float64_t</span><span class=\"p\">[:,</span> <span class=\"p\">:]</span> <span class=\"n\">x_train</span><span class=\"p\">,</span></pre>\n",
       "<pre class='cython code score-103 '>/* Python wrapper */\n",
       "static PyObject *__pyx_pw_46_cython_magic_068b7d05edfe1c28296fa0d160e3f997_1rbf_derivative_cython(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/\n",
       "static char __pyx_doc_46_cython_magic_068b7d05edfe1c28296fa0d160e3f997_rbf_derivative_cython[] = \"This function calculates the rbf derivative using\\n    Cython. It has been fairly optimized and provides x100\\n    speedup over the original python function.\\n    \\n    Parameters\\n    ----------\\n    x_train : array, [N x D], int64\\n        The training data used to find the kernel model.\\n\\n    x_function  : array, [M x D], int64\\n        The test points (or vector) to use.\\n\\n    weights   : array, [N x D], float64\\n        The weights found from the kernel model\\n            y = K * weights\\n\\n    kernel_mat: array, [N x M], float64\\n        The rbf kernel matrix with the similarities between the test\\n        points and the training points.\\n\\n    n_derivative : int, (default = 1) {1, 2}, int\\n        chooses which nth derivative to calculate\\n\\n    gamma : float, default: None, float64\\n        the parameter for the rbf_kernel matrix function\\n\\n    Returns\\n    -------\\n\\n    derivative : array, [M x D]\\n        returns the derivative with respect to training points used in\\n        the kernel model and the test points.\\n\\n    Information\\n    -----------\\n    Author: Juan Emmanuel Johnson\\n    Email : jej2744@rit.edu\\n            juan.johnson@uv.es\\n    \";\n",
       "static PyMethodDef __pyx_mdef_46_cython_magic_068b7d05edfe1c28296fa0d160e3f997_1rbf_derivative_cython = {\"rbf_derivative_cython\", (PyCFunction)__pyx_pw_46_cython_magic_068b7d05edfe1c28296fa0d160e3f997_1rbf_derivative_cython, METH_VARARGS|METH_KEYWORDS, __pyx_doc_46_cython_magic_068b7d05edfe1c28296fa0d160e3f997_rbf_derivative_cython};\n",
       "static PyObject *__pyx_pw_46_cython_magic_068b7d05edfe1c28296fa0d160e3f997_1rbf_derivative_cython(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {\n",
       "  __Pyx_memviewslice __pyx_v_x_train = { 0, 0, { 0 }, { 0 }, { 0 } };\n",
       "  __Pyx_memviewslice __pyx_v_x_function = { 0, 0, { 0 }, { 0 }, { 0 } };\n",
       "  __Pyx_memviewslice __pyx_v_weights = { 0, 0, { 0 }, { 0 }, { 0 } };\n",
       "  __Pyx_memviewslice __pyx_v_kernel_mat = { 0, 0, { 0 }, { 0 }, { 0 } };\n",
       "  __pyx_t_5numpy_int_t __pyx_v_n_derivative;\n",
       "  __pyx_t_5numpy_float64_t __pyx_v_gamma;\n",
       "  PyObject *__pyx_r = 0;\n",
       "  <span class='refnanny'>__Pyx_RefNannyDeclarations</span>\n",
       "  <span class='refnanny'>__Pyx_RefNannySetupContext</span>(\"rbf_derivative_cython (wrapper)\", 0);\n",
       "  {\n",
       "    static PyObject **__pyx_pyargnames[] = {&amp;__pyx_n_s_x_train,&amp;__pyx_n_s_x_function,&amp;__pyx_n_s_weights,&amp;__pyx_n_s_kernel_mat,&amp;__pyx_n_s_n_derivative,&amp;__pyx_n_s_gamma,0};\n",
       "    PyObject* values[6] = {0,0,0,0,0,0};\n",
       "    if (unlikely(__pyx_kwds)) {\n",
       "      Py_ssize_t kw_args;\n",
       "      const Py_ssize_t pos_args = <span class='py_macro_api'>PyTuple_GET_SIZE</span>(__pyx_args);\n",
       "      switch (pos_args) {\n",
       "        case  6: values[5] = <span class='py_macro_api'>PyTuple_GET_ITEM</span>(__pyx_args, 5);\n",
       "        CYTHON_FALLTHROUGH;\n",
       "        case  5: values[4] = <span class='py_macro_api'>PyTuple_GET_ITEM</span>(__pyx_args, 4);\n",
       "        CYTHON_FALLTHROUGH;\n",
       "        case  4: values[3] = <span class='py_macro_api'>PyTuple_GET_ITEM</span>(__pyx_args, 3);\n",
       "        CYTHON_FALLTHROUGH;\n",
       "        case  3: values[2] = <span class='py_macro_api'>PyTuple_GET_ITEM</span>(__pyx_args, 2);\n",
       "        CYTHON_FALLTHROUGH;\n",
       "        case  2: values[1] = <span class='py_macro_api'>PyTuple_GET_ITEM</span>(__pyx_args, 1);\n",
       "        CYTHON_FALLTHROUGH;\n",
       "        case  1: values[0] = <span class='py_macro_api'>PyTuple_GET_ITEM</span>(__pyx_args, 0);\n",
       "        CYTHON_FALLTHROUGH;\n",
       "        case  0: break;\n",
       "        default: goto __pyx_L5_argtuple_error;\n",
       "      }\n",
       "      kw_args = <span class='py_c_api'>PyDict_Size</span>(__pyx_kwds);\n",
       "      switch (pos_args) {\n",
       "        case  0:\n",
       "        if (likely((values[0] = <span class='py_c_api'>PyDict_GetItem</span>(__pyx_kwds, __pyx_n_s_x_train)) != 0)) kw_args--;\n",
       "        else goto __pyx_L5_argtuple_error;\n",
       "        CYTHON_FALLTHROUGH;\n",
       "        case  1:\n",
       "        if (likely((values[1] = <span class='py_c_api'>PyDict_GetItem</span>(__pyx_kwds, __pyx_n_s_x_function)) != 0)) kw_args--;\n",
       "        else {\n",
       "          <span class='pyx_c_api'>__Pyx_RaiseArgtupleInvalid</span>(\"rbf_derivative_cython\", 1, 6, 6, 1); <span class='error_goto'>__PYX_ERR(0, 8, __pyx_L3_error)</span>\n",
       "        }\n",
       "        CYTHON_FALLTHROUGH;\n",
       "        case  2:\n",
       "        if (likely((values[2] = <span class='py_c_api'>PyDict_GetItem</span>(__pyx_kwds, __pyx_n_s_weights)) != 0)) kw_args--;\n",
       "        else {\n",
       "          <span class='pyx_c_api'>__Pyx_RaiseArgtupleInvalid</span>(\"rbf_derivative_cython\", 1, 6, 6, 2); <span class='error_goto'>__PYX_ERR(0, 8, __pyx_L3_error)</span>\n",
       "        }\n",
       "        CYTHON_FALLTHROUGH;\n",
       "        case  3:\n",
       "        if (likely((values[3] = <span class='py_c_api'>PyDict_GetItem</span>(__pyx_kwds, __pyx_n_s_kernel_mat)) != 0)) kw_args--;\n",
       "        else {\n",
       "          <span class='pyx_c_api'>__Pyx_RaiseArgtupleInvalid</span>(\"rbf_derivative_cython\", 1, 6, 6, 3); <span class='error_goto'>__PYX_ERR(0, 8, __pyx_L3_error)</span>\n",
       "        }\n",
       "        CYTHON_FALLTHROUGH;\n",
       "        case  4:\n",
       "        if (likely((values[4] = <span class='py_c_api'>PyDict_GetItem</span>(__pyx_kwds, __pyx_n_s_n_derivative)) != 0)) kw_args--;\n",
       "        else {\n",
       "          <span class='pyx_c_api'>__Pyx_RaiseArgtupleInvalid</span>(\"rbf_derivative_cython\", 1, 6, 6, 4); <span class='error_goto'>__PYX_ERR(0, 8, __pyx_L3_error)</span>\n",
       "        }\n",
       "        CYTHON_FALLTHROUGH;\n",
       "        case  5:\n",
       "        if (likely((values[5] = <span class='py_c_api'>PyDict_GetItem</span>(__pyx_kwds, __pyx_n_s_gamma)) != 0)) kw_args--;\n",
       "        else {\n",
       "          <span class='pyx_c_api'>__Pyx_RaiseArgtupleInvalid</span>(\"rbf_derivative_cython\", 1, 6, 6, 5); <span class='error_goto'>__PYX_ERR(0, 8, __pyx_L3_error)</span>\n",
       "        }\n",
       "      }\n",
       "      if (unlikely(kw_args &gt; 0)) {\n",
       "        if (unlikely(<span class='pyx_c_api'>__Pyx_ParseOptionalKeywords</span>(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, \"rbf_derivative_cython\") &lt; 0)) <span class='error_goto'>__PYX_ERR(0, 8, __pyx_L3_error)</span>\n",
       "      }\n",
       "    } else if (<span class='py_macro_api'>PyTuple_GET_SIZE</span>(__pyx_args) != 6) {\n",
       "      goto __pyx_L5_argtuple_error;\n",
       "    } else {\n",
       "      values[0] = <span class='py_macro_api'>PyTuple_GET_ITEM</span>(__pyx_args, 0);\n",
       "      values[1] = <span class='py_macro_api'>PyTuple_GET_ITEM</span>(__pyx_args, 1);\n",
       "      values[2] = <span class='py_macro_api'>PyTuple_GET_ITEM</span>(__pyx_args, 2);\n",
       "      values[3] = <span class='py_macro_api'>PyTuple_GET_ITEM</span>(__pyx_args, 3);\n",
       "      values[4] = <span class='py_macro_api'>PyTuple_GET_ITEM</span>(__pyx_args, 4);\n",
       "      values[5] = <span class='py_macro_api'>PyTuple_GET_ITEM</span>(__pyx_args, 5);\n",
       "    }\n",
       "    __pyx_v_x_train = __Pyx_PyObject_to_MemoryviewSlice_dsds_nn___pyx_t_5numpy_float64_t(values[0]);<span class='error_goto'> if (unlikely(!__pyx_v_x_train.memview)) __PYX_ERR(0, 8, __pyx_L3_error)</span>\n",
       "    __pyx_v_x_function = __Pyx_PyObject_to_MemoryviewSlice_dsds_nn___pyx_t_5numpy_float64_t(values[1]);<span class='error_goto'> if (unlikely(!__pyx_v_x_function.memview)) __PYX_ERR(0, 9, __pyx_L3_error)</span>\n",
       "    __pyx_v_weights = __Pyx_PyObject_to_MemoryviewSlice_ds_nn___pyx_t_5numpy_float64_t(values[2]);<span class='error_goto'> if (unlikely(!__pyx_v_weights.memview)) __PYX_ERR(0, 10, __pyx_L3_error)</span>\n",
       "    __pyx_v_kernel_mat = __Pyx_PyObject_to_MemoryviewSlice_dsds_nn___pyx_t_5numpy_float64_t(values[3]);<span class='error_goto'> if (unlikely(!__pyx_v_kernel_mat.memview)) __PYX_ERR(0, 11, __pyx_L3_error)</span>\n",
       "    __pyx_v_n_derivative = <span class='pyx_c_api'>__Pyx_PyInt_As_npy_long</span>(values[4]); if (unlikely((__pyx_v_n_derivative == ((npy_long)-1)) &amp;&amp; <span class='py_c_api'>PyErr_Occurred</span>())) <span class='error_goto'>__PYX_ERR(0, 12, __pyx_L3_error)</span>\n",
       "    __pyx_v_gamma = __pyx_<span class='py_c_api'>PyFloat_AsDouble</span>(values[5]); if (unlikely((__pyx_v_gamma == ((npy_float64)-1)) &amp;&amp; <span class='py_c_api'>PyErr_Occurred</span>())) <span class='error_goto'>__PYX_ERR(0, 13, __pyx_L3_error)</span>\n",
       "  }\n",
       "  goto __pyx_L4_argument_unpacking_done;\n",
       "  __pyx_L5_argtuple_error:;\n",
       "  <span class='pyx_c_api'>__Pyx_RaiseArgtupleInvalid</span>(\"rbf_derivative_cython\", 1, 6, 6, <span class='py_macro_api'>PyTuple_GET_SIZE</span>(__pyx_args)); <span class='error_goto'>__PYX_ERR(0, 8, __pyx_L3_error)</span>\n",
       "  __pyx_L3_error:;\n",
       "  <span class='pyx_c_api'>__Pyx_AddTraceback</span>(\"_cython_magic_068b7d05edfe1c28296fa0d160e3f997.rbf_derivative_cython\", __pyx_clineno, __pyx_lineno, __pyx_filename);\n",
       "  <span class='refnanny'>__Pyx_RefNannyFinishContext</span>();\n",
       "  return NULL;\n",
       "  __pyx_L4_argument_unpacking_done:;\n",
       "  __pyx_r = __pyx_pf_46_cython_magic_068b7d05edfe1c28296fa0d160e3f997_rbf_derivative_cython(__pyx_self, __pyx_v_x_train, __pyx_v_x_function, __pyx_v_weights, __pyx_v_kernel_mat, __pyx_v_n_derivative, __pyx_v_gamma);\n",
       "\n",
       "  /* function exit code */\n",
       "  <span class='refnanny'>__Pyx_RefNannyFinishContext</span>();\n",
       "  return __pyx_r;\n",
       "}\n",
       "\n",
       "static PyObject *__pyx_pf_46_cython_magic_068b7d05edfe1c28296fa0d160e3f997_rbf_derivative_cython(CYTHON_UNUSED PyObject *__pyx_self, __Pyx_memviewslice __pyx_v_x_train, __Pyx_memviewslice __pyx_v_x_function, __Pyx_memviewslice __pyx_v_weights, __Pyx_memviewslice __pyx_v_kernel_mat, __pyx_t_5numpy_int_t __pyx_v_n_derivative, __pyx_t_5numpy_float64_t __pyx_v_gamma) {\n",
       "  int __pyx_v_d_dimensions;\n",
       "  int __pyx_v_n_test;\n",
       "  int __pyx_v_n_train;\n",
       "  int __pyx_v_idim;\n",
       "  int __pyx_v_iTest;\n",
       "  int __pyx_v_iTrain;\n",
       "  __Pyx_memviewslice __pyx_v_derivative = { 0, 0, { 0 }, { 0 }, { 0 } };\n",
       "  __pyx_t_5numpy_float64_t __pyx_v_theta;\n",
       "  int __pyx_v_dim;\n",
       "  PyObject *__pyx_r = NULL;\n",
       "  <span class='refnanny'>__Pyx_RefNannyDeclarations</span>\n",
       "  <span class='refnanny'>__Pyx_RefNannySetupContext</span>(\"rbf_derivative_cython\", 0);\n",
       "/* … */\n",
       "  /* function exit code */\n",
       "  __pyx_L1_error:;\n",
       "  <span class='pyx_macro_api'>__Pyx_XDECREF</span>(__pyx_t_1);\n",
       "  <span class='pyx_macro_api'>__Pyx_XDECREF</span>(__pyx_t_2);\n",
       "  <span class='pyx_macro_api'>__Pyx_XDECREF</span>(__pyx_t_3);\n",
       "  <span class='pyx_macro_api'>__Pyx_XDECREF</span>(__pyx_t_4);\n",
       "  <span class='pyx_macro_api'>__Pyx_XDECREF</span>(__pyx_t_5);\n",
       "  __PYX_XDEC_MEMVIEW(&amp;__pyx_t_6, 1);\n",
       "  <span class='pyx_c_api'>__Pyx_AddTraceback</span>(\"_cython_magic_068b7d05edfe1c28296fa0d160e3f997.rbf_derivative_cython\", __pyx_clineno, __pyx_lineno, __pyx_filename);\n",
       "  __pyx_r = NULL;\n",
       "  __pyx_L0:;\n",
       "  __PYX_XDEC_MEMVIEW(&amp;__pyx_v_derivative, 1);\n",
       "  __PYX_XDEC_MEMVIEW(&amp;__pyx_v_x_train, 1);\n",
       "  __PYX_XDEC_MEMVIEW(&amp;__pyx_v_x_function, 1);\n",
       "  __PYX_XDEC_MEMVIEW(&amp;__pyx_v_weights, 1);\n",
       "  __PYX_XDEC_MEMVIEW(&amp;__pyx_v_kernel_mat, 1);\n",
       "  <span class='refnanny'>__Pyx_XGIVEREF</span>(__pyx_r);\n",
       "  <span class='refnanny'>__Pyx_RefNannyFinishContext</span>();\n",
       "  return __pyx_r;\n",
       "}\n",
       "/* … */\n",
       "  __pyx_tuple__30 = <span class='py_c_api'>PyTuple_Pack</span>(15, __pyx_n_s_x_train, __pyx_n_s_x_function, __pyx_n_s_weights, __pyx_n_s_kernel_mat, __pyx_n_s_n_derivative, __pyx_n_s_gamma, __pyx_n_s_d_dimensions, __pyx_n_s_n_test, __pyx_n_s_n_train, __pyx_n_s_idim, __pyx_n_s_iTest, __pyx_n_s_iTrain, __pyx_n_s_derivative, __pyx_n_s_theta, __pyx_n_s_dim);<span class='error_goto'> if (unlikely(!__pyx_tuple__30)) __PYX_ERR(0, 8, __pyx_L1_error)</span>\n",
       "  <span class='refnanny'>__Pyx_GOTREF</span>(__pyx_tuple__30);\n",
       "  <span class='refnanny'>__Pyx_GIVEREF</span>(__pyx_tuple__30);\n",
       "/* … */\n",
       "  __pyx_t_1 = PyCFunction_NewEx(&amp;__pyx_mdef_46_cython_magic_068b7d05edfe1c28296fa0d160e3f997_1rbf_derivative_cython, NULL, __pyx_n_s_cython_magic_068b7d05edfe1c2829);<span class='error_goto'> if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 8, __pyx_L1_error)</span>\n",
       "  <span class='refnanny'>__Pyx_GOTREF</span>(__pyx_t_1);\n",
       "  if (<span class='py_c_api'>PyDict_SetItem</span>(__pyx_d, __pyx_n_s_rbf_derivative_cython, __pyx_t_1) &lt; 0) <span class='error_goto'>__PYX_ERR(0, 8, __pyx_L1_error)</span>\n",
       "  <span class='pyx_macro_api'>__Pyx_DECREF</span>(__pyx_t_1); __pyx_t_1 = 0;\n",
       "  __pyx_codeobj__31 = (PyObject*)<span class='pyx_c_api'>__Pyx_PyCode_New</span>(6, 0, 15, 0, 0, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__30, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_Users_eman_ipython_cython__cyth, __pyx_n_s_rbf_derivative_cython, 8, __pyx_empty_bytes);<span class='error_goto'> if (unlikely(!__pyx_codeobj__31)) __PYX_ERR(0, 8, __pyx_L1_error)</span>\n",
       "</pre><pre class=\"cython line score-0\">&#xA0;<span class=\"\">009</span>:                    <span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">float64_t</span><span class=\"p\">[:,</span> <span class=\"p\">:]</span> <span class=\"n\">x_function</span><span class=\"p\">,</span></pre>\n",
       "<pre class=\"cython line score-0\">&#xA0;<span class=\"\">010</span>:                    <span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">float64_t</span><span class=\"p\">[:]</span> <span class=\"n\">weights</span><span class=\"p\">,</span></pre>\n",
       "<pre class=\"cython line score-0\">&#xA0;<span class=\"\">011</span>:                    <span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">float64_t</span><span class=\"p\">[:,</span> <span class=\"p\">:]</span> <span class=\"n\">kernel_mat</span><span class=\"p\">,</span></pre>\n",
       "<pre class=\"cython line score-0\">&#xA0;<span class=\"\">012</span>:                    <span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">int_t</span> <span class=\"n\">n_derivative</span><span class=\"p\">,</span></pre>\n",
       "<pre class=\"cython line score-0\">&#xA0;<span class=\"\">013</span>:                    <span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">float64_t</span> <span class=\"n\">gamma</span><span class=\"p\">):</span></pre>\n",
       "<pre class=\"cython line score-0\">&#xA0;<span class=\"\">014</span>:     <span class=\"sd\">&quot;&quot;&quot;This function calculates the rbf derivative using</span></pre>\n",
       "<pre class=\"cython line score-0\">&#xA0;<span class=\"\">015</span>: <span class=\"sd\">    Cython. It has been fairly optimized and provides x100</span></pre>\n",
       "<pre class=\"cython line score-0\">&#xA0;<span class=\"\">016</span>: <span class=\"sd\">    speedup over the original python function.</span></pre>\n",
       "<pre class=\"cython line score-0\">&#xA0;<span class=\"\">017</span>: <span class=\"sd\">    </span></pre>\n",
       "<pre class=\"cython line score-0\">&#xA0;<span class=\"\">018</span>: <span class=\"sd\">    Parameters</span></pre>\n",
       "<pre class=\"cython line score-0\">&#xA0;<span class=\"\">019</span>: <span class=\"sd\">    ----------</span></pre>\n",
       "<pre class=\"cython line score-0\">&#xA0;<span class=\"\">020</span>: <span class=\"sd\">    x_train : array, [N x D], int64</span></pre>\n",
       "<pre class=\"cython line score-0\">&#xA0;<span class=\"\">021</span>: <span class=\"sd\">        The training data used to find the kernel model.</span></pre>\n",
       "<pre class=\"cython line score-0\">&#xA0;<span class=\"\">022</span>: </pre>\n",
       "<pre class=\"cython line score-0\">&#xA0;<span class=\"\">023</span>: <span class=\"sd\">    x_function  : array, [M x D], int64</span></pre>\n",
       "<pre class=\"cython line score-0\">&#xA0;<span class=\"\">024</span>: <span class=\"sd\">        The test points (or vector) to use.</span></pre>\n",
       "<pre class=\"cython line score-0\">&#xA0;<span class=\"\">025</span>: </pre>\n",
       "<pre class=\"cython line score-0\">&#xA0;<span class=\"\">026</span>: <span class=\"sd\">    weights   : array, [N x D], float64</span></pre>\n",
       "<pre class=\"cython line score-0\">&#xA0;<span class=\"\">027</span>: <span class=\"sd\">        The weights found from the kernel model</span></pre>\n",
       "<pre class=\"cython line score-0\">&#xA0;<span class=\"\">028</span>: <span class=\"sd\">            y = K * weights</span></pre>\n",
       "<pre class=\"cython line score-0\">&#xA0;<span class=\"\">029</span>: </pre>\n",
       "<pre class=\"cython line score-0\">&#xA0;<span class=\"\">030</span>: <span class=\"sd\">    kernel_mat: array, [N x M], float64</span></pre>\n",
       "<pre class=\"cython line score-0\">&#xA0;<span class=\"\">031</span>: <span class=\"sd\">        The rbf kernel matrix with the similarities between the test</span></pre>\n",
       "<pre class=\"cython line score-0\">&#xA0;<span class=\"\">032</span>: <span class=\"sd\">        points and the training points.</span></pre>\n",
       "<pre class=\"cython line score-0\">&#xA0;<span class=\"\">033</span>: </pre>\n",
       "<pre class=\"cython line score-0\">&#xA0;<span class=\"\">034</span>: <span class=\"sd\">    n_derivative : int, (default = 1) {1, 2}, int</span></pre>\n",
       "<pre class=\"cython line score-0\">&#xA0;<span class=\"\">035</span>: <span class=\"sd\">        chooses which nth derivative to calculate</span></pre>\n",
       "<pre class=\"cython line score-0\">&#xA0;<span class=\"\">036</span>: </pre>\n",
       "<pre class=\"cython line score-0\">&#xA0;<span class=\"\">037</span>: <span class=\"sd\">    gamma : float, default: None, float64</span></pre>\n",
       "<pre class=\"cython line score-0\">&#xA0;<span class=\"\">038</span>: <span class=\"sd\">        the parameter for the rbf_kernel matrix function</span></pre>\n",
       "<pre class=\"cython line score-0\">&#xA0;<span class=\"\">039</span>: </pre>\n",
       "<pre class=\"cython line score-0\">&#xA0;<span class=\"\">040</span>: <span class=\"sd\">    Returns</span></pre>\n",
       "<pre class=\"cython line score-0\">&#xA0;<span class=\"\">041</span>: <span class=\"sd\">    -------</span></pre>\n",
       "<pre class=\"cython line score-0\">&#xA0;<span class=\"\">042</span>: </pre>\n",
       "<pre class=\"cython line score-0\">&#xA0;<span class=\"\">043</span>: <span class=\"sd\">    derivative : array, [M x D]</span></pre>\n",
       "<pre class=\"cython line score-0\">&#xA0;<span class=\"\">044</span>: <span class=\"sd\">        returns the derivative with respect to training points used in</span></pre>\n",
       "<pre class=\"cython line score-0\">&#xA0;<span class=\"\">045</span>: <span class=\"sd\">        the kernel model and the test points.</span></pre>\n",
       "<pre class=\"cython line score-0\">&#xA0;<span class=\"\">046</span>: </pre>\n",
       "<pre class=\"cython line score-0\">&#xA0;<span class=\"\">047</span>: <span class=\"sd\">    Information</span></pre>\n",
       "<pre class=\"cython line score-0\">&#xA0;<span class=\"\">048</span>: <span class=\"sd\">    -----------</span></pre>\n",
       "<pre class=\"cython line score-0\">&#xA0;<span class=\"\">049</span>: <span class=\"sd\">    Author: Juan Emmanuel Johnson</span></pre>\n",
       "<pre class=\"cython line score-0\">&#xA0;<span class=\"\">050</span>: <span class=\"sd\">    Email : jej2744@rit.edu</span></pre>\n",
       "<pre class=\"cython line score-0\">&#xA0;<span class=\"\">051</span>: <span class=\"sd\">            juan.johnson@uv.es</span></pre>\n",
       "<pre class=\"cython line score-0\">&#xA0;<span class=\"\">052</span>: <span class=\"sd\">    &quot;&quot;&quot;</span></pre>\n",
       "<pre class=\"cython line score-0\" onclick='toggleDiv(this)'>+<span class=\"\">053</span>:     <span class=\"k\">cdef</span> <span class=\"kt\">int</span> <span class=\"nf\">d_dimensions</span> <span class=\"o\">=</span> <span class=\"n\">x_function</span><span class=\"o\">.</span><span class=\"n\">shape</span><span class=\"p\">[</span><span class=\"mf\">1</span><span class=\"p\">]</span></pre>\n",
       "<pre class='cython code score-0 '>  __pyx_v_d_dimensions = (__pyx_v_x_function.shape[1]);\n",
       "</pre><pre class=\"cython line score-0\" onclick='toggleDiv(this)'>+<span class=\"\">054</span>:     <span class=\"k\">cdef</span> <span class=\"kt\">int</span> <span class=\"nf\">n_test</span> <span class=\"o\">=</span> <span class=\"n\">x_function</span><span class=\"o\">.</span><span class=\"n\">shape</span><span class=\"p\">[</span><span class=\"mf\">0</span><span class=\"p\">]</span></pre>\n",
       "<pre class='cython code score-0 '>  __pyx_v_n_test = (__pyx_v_x_function.shape[0]);\n",
       "</pre><pre class=\"cython line score-0\" onclick='toggleDiv(this)'>+<span class=\"\">055</span>:     <span class=\"k\">cdef</span> <span class=\"kt\">int</span> <span class=\"nf\">n_train</span> <span class=\"o\">=</span> <span class=\"n\">x_train</span><span class=\"o\">.</span><span class=\"n\">shape</span><span class=\"p\">[</span><span class=\"mf\">0</span><span class=\"p\">]</span></pre>\n",
       "<pre class='cython code score-0 '>  __pyx_v_n_train = (__pyx_v_x_train.shape[0]);\n",
       "</pre><pre class=\"cython line score-0\">&#xA0;<span class=\"\">056</span>:     <span class=\"k\">cdef</span> <span class=\"kt\">int</span> <span class=\"nf\">idim</span><span class=\"p\">,</span> <span class=\"nf\">iTest</span><span class=\"p\">,</span> <span class=\"nf\">iTrain</span></pre>\n",
       "<pre class=\"cython line score-0\">&#xA0;<span class=\"\">057</span>: </pre>\n",
       "<pre class=\"cython line score-0\">&#xA0;<span class=\"\">058</span>:     <span class=\"c\"># initialize the derivative</span></pre>\n",
       "<pre class=\"cython line score-56\" onclick='toggleDiv(this)'>+<span class=\"\">059</span>:     <span class=\"k\">cdef</span> <span class=\"kt\">np</span>.<span class=\"kt\">float64_t</span>[<span class=\"p\">:,:]</span> <span class=\"n\">derivative</span> <span class=\"o\">=</span> <span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">zeros</span><span class=\"p\">((</span><span class=\"n\">n_test</span><span class=\"p\">,</span> <span class=\"n\">d_dimensions</span><span class=\"p\">))</span></pre>\n",
       "<pre class='cython code score-56 '>  __pyx_t_2 = <span class='pyx_c_api'>__Pyx_GetModuleGlobalName</span>(__pyx_n_s_np);<span class='error_goto'> if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 59, __pyx_L1_error)</span>\n",
       "  <span class='refnanny'>__Pyx_GOTREF</span>(__pyx_t_2);\n",
       "  __pyx_t_3 = <span class='pyx_c_api'>__Pyx_PyObject_GetAttrStr</span>(__pyx_t_2, __pyx_n_s_zeros);<span class='error_goto'> if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 59, __pyx_L1_error)</span>\n",
       "  <span class='refnanny'>__Pyx_GOTREF</span>(__pyx_t_3);\n",
       "  <span class='pyx_macro_api'>__Pyx_DECREF</span>(__pyx_t_2); __pyx_t_2 = 0;\n",
       "  __pyx_t_2 = <span class='pyx_c_api'>__Pyx_PyInt_From_int</span>(__pyx_v_n_test);<span class='error_goto'> if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 59, __pyx_L1_error)</span>\n",
       "  <span class='refnanny'>__Pyx_GOTREF</span>(__pyx_t_2);\n",
       "  __pyx_t_4 = <span class='pyx_c_api'>__Pyx_PyInt_From_int</span>(__pyx_v_d_dimensions);<span class='error_goto'> if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 59, __pyx_L1_error)</span>\n",
       "  <span class='refnanny'>__Pyx_GOTREF</span>(__pyx_t_4);\n",
       "  __pyx_t_5 = <span class='py_c_api'>PyTuple_New</span>(2);<span class='error_goto'> if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 59, __pyx_L1_error)</span>\n",
       "  <span class='refnanny'>__Pyx_GOTREF</span>(__pyx_t_5);\n",
       "  <span class='refnanny'>__Pyx_GIVEREF</span>(__pyx_t_2);\n",
       "  <span class='py_macro_api'>PyTuple_SET_ITEM</span>(__pyx_t_5, 0, __pyx_t_2);\n",
       "  <span class='refnanny'>__Pyx_GIVEREF</span>(__pyx_t_4);\n",
       "  <span class='py_macro_api'>PyTuple_SET_ITEM</span>(__pyx_t_5, 1, __pyx_t_4);\n",
       "  __pyx_t_2 = 0;\n",
       "  __pyx_t_4 = 0;\n",
       "  __pyx_t_4 = NULL;\n",
       "  if (CYTHON_UNPACK_METHODS &amp;&amp; unlikely(<span class='py_c_api'>PyMethod_Check</span>(__pyx_t_3))) {\n",
       "    __pyx_t_4 = <span class='py_macro_api'>PyMethod_GET_SELF</span>(__pyx_t_3);\n",
       "    if (likely(__pyx_t_4)) {\n",
       "      PyObject* function = <span class='py_macro_api'>PyMethod_GET_FUNCTION</span>(__pyx_t_3);\n",
       "      <span class='pyx_macro_api'>__Pyx_INCREF</span>(__pyx_t_4);\n",
       "      <span class='pyx_macro_api'>__Pyx_INCREF</span>(function);\n",
       "      <span class='pyx_macro_api'>__Pyx_DECREF_SET</span>(__pyx_t_3, function);\n",
       "    }\n",
       "  }\n",
       "  if (!__pyx_t_4) {\n",
       "    __pyx_t_1 = <span class='pyx_c_api'>__Pyx_PyObject_CallOneArg</span>(__pyx_t_3, __pyx_t_5);<span class='error_goto'> if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 59, __pyx_L1_error)</span>\n",
       "    <span class='pyx_macro_api'>__Pyx_DECREF</span>(__pyx_t_5); __pyx_t_5 = 0;\n",
       "    <span class='refnanny'>__Pyx_GOTREF</span>(__pyx_t_1);\n",
       "  } else {\n",
       "    #if CYTHON_FAST_PYCALL\n",
       "    if (<span class='py_c_api'>PyFunction_Check</span>(__pyx_t_3)) {\n",
       "      PyObject *__pyx_temp[2] = {__pyx_t_4, __pyx_t_5};\n",
       "      __pyx_t_1 = <span class='pyx_c_api'>__Pyx_PyFunction_FastCall</span>(__pyx_t_3, __pyx_temp+1-1, 1+1);<span class='error_goto'> if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 59, __pyx_L1_error)</span>\n",
       "      <span class='pyx_macro_api'>__Pyx_XDECREF</span>(__pyx_t_4); __pyx_t_4 = 0;\n",
       "      <span class='refnanny'>__Pyx_GOTREF</span>(__pyx_t_1);\n",
       "      <span class='pyx_macro_api'>__Pyx_DECREF</span>(__pyx_t_5); __pyx_t_5 = 0;\n",
       "    } else\n",
       "    #endif\n",
       "    #if CYTHON_FAST_PYCCALL\n",
       "    if (<span class='pyx_c_api'>__Pyx_PyFastCFunction_Check</span>(__pyx_t_3)) {\n",
       "      PyObject *__pyx_temp[2] = {__pyx_t_4, __pyx_t_5};\n",
       "      __pyx_t_1 = <span class='pyx_c_api'>__Pyx_PyCFunction_FastCall</span>(__pyx_t_3, __pyx_temp+1-1, 1+1);<span class='error_goto'> if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 59, __pyx_L1_error)</span>\n",
       "      <span class='pyx_macro_api'>__Pyx_XDECREF</span>(__pyx_t_4); __pyx_t_4 = 0;\n",
       "      <span class='refnanny'>__Pyx_GOTREF</span>(__pyx_t_1);\n",
       "      <span class='pyx_macro_api'>__Pyx_DECREF</span>(__pyx_t_5); __pyx_t_5 = 0;\n",
       "    } else\n",
       "    #endif\n",
       "    {\n",
       "      __pyx_t_2 = <span class='py_c_api'>PyTuple_New</span>(1+1);<span class='error_goto'> if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 59, __pyx_L1_error)</span>\n",
       "      <span class='refnanny'>__Pyx_GOTREF</span>(__pyx_t_2);\n",
       "      <span class='refnanny'>__Pyx_GIVEREF</span>(__pyx_t_4); <span class='py_macro_api'>PyTuple_SET_ITEM</span>(__pyx_t_2, 0, __pyx_t_4); __pyx_t_4 = NULL;\n",
       "      <span class='refnanny'>__Pyx_GIVEREF</span>(__pyx_t_5);\n",
       "      <span class='py_macro_api'>PyTuple_SET_ITEM</span>(__pyx_t_2, 0+1, __pyx_t_5);\n",
       "      __pyx_t_5 = 0;\n",
       "      __pyx_t_1 = <span class='pyx_c_api'>__Pyx_PyObject_Call</span>(__pyx_t_3, __pyx_t_2, NULL);<span class='error_goto'> if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 59, __pyx_L1_error)</span>\n",
       "      <span class='refnanny'>__Pyx_GOTREF</span>(__pyx_t_1);\n",
       "      <span class='pyx_macro_api'>__Pyx_DECREF</span>(__pyx_t_2); __pyx_t_2 = 0;\n",
       "    }\n",
       "  }\n",
       "  <span class='pyx_macro_api'>__Pyx_DECREF</span>(__pyx_t_3); __pyx_t_3 = 0;\n",
       "  __pyx_t_6 = __Pyx_PyObject_to_MemoryviewSlice_dsds_nn___pyx_t_5numpy_float64_t(__pyx_t_1);\n",
       "  if (unlikely(!__pyx_t_6.memview)) <span class='error_goto'>__PYX_ERR(0, 59, __pyx_L1_error)</span>\n",
       "  <span class='pyx_macro_api'>__Pyx_DECREF</span>(__pyx_t_1); __pyx_t_1 = 0;\n",
       "  __pyx_v_derivative = __pyx_t_6;\n",
       "  __pyx_t_6.memview = NULL;\n",
       "  __pyx_t_6.data = NULL;\n",
       "</pre><pre class=\"cython line score-0\">&#xA0;<span class=\"\">060</span>: </pre>\n",
       "<pre class=\"cython line score-0\">&#xA0;<span class=\"\">061</span>:     <span class=\"c\"># consolidate the parameters</span></pre>\n",
       "<pre class=\"cython line score-0\" onclick='toggleDiv(this)'>+<span class=\"\">062</span>:     <span class=\"k\">cdef</span> <span class=\"kt\">np</span>.<span class=\"kt\">float64_t</span> <span class=\"nf\">theta</span> <span class=\"o\">=</span> <span class=\"mf\">2.0</span> <span class=\"o\">*</span> <span class=\"n\">gamma</span></pre>\n",
       "<pre class='cython code score-0 '>  __pyx_v_theta = (2.0 * __pyx_v_gamma);\n",
       "</pre><pre class=\"cython line score-0\">&#xA0;<span class=\"\">063</span>: </pre>\n",
       "<pre class=\"cython line score-0\">&#xA0;<span class=\"\">064</span>: </pre>\n",
       "<pre class=\"cython line score-0\" onclick='toggleDiv(this)'>+<span class=\"\">065</span>:     <span class=\"k\">if</span> <span class=\"n\">n_derivative</span> <span class=\"o\">==</span> <span class=\"mf\">1</span><span class=\"p\">:</span></pre>\n",
       "<pre class='cython code score-0 '>  switch (__pyx_v_n_derivative) {\n",
       "    case 1:\n",
       "/* … */\n",
       "    break;\n",
       "</pre><pre class=\"cython line score-0\">&#xA0;<span class=\"\">066</span>: </pre>\n",
       "<pre class=\"cython line score-0\">&#xA0;<span class=\"\">067</span>:         <span class=\"c\"># loop through dimensions</span></pre>\n",
       "<pre class=\"cython line score-0\" onclick='toggleDiv(this)'>+<span class=\"\">068</span>:         <span class=\"k\">for</span> <span class=\"n\">idim</span> <span class=\"ow\">in</span> <span class=\"nb\">range</span><span class=\"p\">(</span><span class=\"n\">d_dimensions</span><span class=\"p\">):</span></pre>\n",
       "<pre class='cython code score-0 '>    __pyx_t_7 = __pyx_v_d_dimensions;\n",
       "    for (__pyx_t_8 = 0; __pyx_t_8 &lt; __pyx_t_7; __pyx_t_8+=1) {\n",
       "      __pyx_v_idim = __pyx_t_8;\n",
       "</pre><pre class=\"cython line score-0\">&#xA0;<span class=\"\">069</span>: </pre>\n",
       "<pre class=\"cython line score-0\">&#xA0;<span class=\"\">070</span>:             <span class=\"c\"># loop through the number of test points</span></pre>\n",
       "<pre class=\"cython line score-0\" onclick='toggleDiv(this)'>+<span class=\"\">071</span>:             <span class=\"k\">for</span> <span class=\"n\">iTest</span> <span class=\"ow\">in</span> <span class=\"nb\">range</span><span class=\"p\">(</span><span class=\"n\">n_test</span><span class=\"p\">):</span></pre>\n",
       "<pre class='cython code score-0 '>      __pyx_t_9 = __pyx_v_n_test;\n",
       "      for (__pyx_t_10 = 0; __pyx_t_10 &lt; __pyx_t_9; __pyx_t_10+=1) {\n",
       "        __pyx_v_iTest = __pyx_t_10;\n",
       "</pre><pre class=\"cython line score-0\">&#xA0;<span class=\"\">072</span>: </pre>\n",
       "<pre class=\"cython line score-0\">&#xA0;<span class=\"\">073</span>:                 <span class=\"c\"># loop through the number of test points</span></pre>\n",
       "<pre class=\"cython line score-0\" onclick='toggleDiv(this)'>+<span class=\"\">074</span>:                 <span class=\"k\">for</span> <span class=\"n\">iTrain</span> <span class=\"ow\">in</span> <span class=\"nb\">range</span><span class=\"p\">(</span><span class=\"n\">n_train</span><span class=\"p\">):</span></pre>\n",
       "<pre class='cython code score-0 '>        __pyx_t_11 = __pyx_v_n_train;\n",
       "        for (__pyx_t_12 = 0; __pyx_t_12 &lt; __pyx_t_11; __pyx_t_12+=1) {\n",
       "          __pyx_v_iTrain = __pyx_t_12;\n",
       "</pre><pre class=\"cython line score-0\">&#xA0;<span class=\"\">075</span>: </pre>\n",
       "<pre class=\"cython line score-0\">&#xA0;<span class=\"\">076</span>:                     <span class=\"c\"># calculate the derivative for the test points</span></pre>\n",
       "<pre class=\"cython line score-0\" onclick='toggleDiv(this)'>+<span class=\"\">077</span>:                     <span class=\"n\">derivative</span><span class=\"p\">[</span><span class=\"n\">iTest</span><span class=\"p\">,</span> <span class=\"n\">idim</span><span class=\"p\">]</span> <span class=\"o\">+=</span> <span class=\"n\">theta</span> <span class=\"o\">*</span> <span class=\"n\">weights</span><span class=\"p\">[</span><span class=\"n\">iTrain</span><span class=\"p\">]</span> <span class=\"o\">*</span> \\</pre>\n",
       "<pre class='cython code score-0 '>          __pyx_t_13 = __pyx_v_iTrain;\n",
       "/* … */\n",
       "          __pyx_t_20 = __pyx_v_iTest;\n",
       "          __pyx_t_21 = __pyx_v_idim;\n",
       "          *((__pyx_t_5numpy_float64_t *) ( /* dim=1 */ (( /* dim=0 */ (__pyx_v_derivative.data + __pyx_t_20 * __pyx_v_derivative.strides[0]) ) + __pyx_t_21 * __pyx_v_derivative.strides[1]) )) += (((__pyx_v_theta * (*((__pyx_t_5numpy_float64_t *) ( /* dim=0 */ (__pyx_v_weights.data + __pyx_t_13 * __pyx_v_weights.strides[0]) )))) * ((*((__pyx_t_5numpy_float64_t *) ( /* dim=1 */ (( /* dim=0 */ (__pyx_v_x_train.data + __pyx_t_14 * __pyx_v_x_train.strides[0]) ) + __pyx_t_15 * __pyx_v_x_train.strides[1]) ))) - (*((__pyx_t_5numpy_float64_t *) ( /* dim=1 */ (( /* dim=0 */ (__pyx_v_x_function.data + __pyx_t_16 * __pyx_v_x_function.strides[0]) ) + __pyx_t_17 * __pyx_v_x_function.strides[1]) ))))) * (*((__pyx_t_5numpy_float64_t *) ( /* dim=1 */ (( /* dim=0 */ (__pyx_v_kernel_mat.data + __pyx_t_18 * __pyx_v_kernel_mat.strides[0]) ) + __pyx_t_19 * __pyx_v_kernel_mat.strides[1]) ))));\n",
       "        }\n",
       "      }\n",
       "    }\n",
       "</pre><pre class=\"cython line score-0\" onclick='toggleDiv(this)'>+<span class=\"\">078</span>:                                               <span class=\"p\">(</span><span class=\"n\">x_train</span><span class=\"p\">[</span><span class=\"n\">iTrain</span><span class=\"p\">,</span> <span class=\"n\">idim</span><span class=\"p\">]</span> <span class=\"o\">-</span></pre>\n",
       "<pre class='cython code score-0 '>          __pyx_t_14 = __pyx_v_iTrain;\n",
       "          __pyx_t_15 = __pyx_v_idim;\n",
       "</pre><pre class=\"cython line score-0\" onclick='toggleDiv(this)'>+<span class=\"\">079</span>:                                                <span class=\"n\">x_function</span><span class=\"p\">[</span><span class=\"n\">iTest</span><span class=\"p\">,</span> <span class=\"n\">idim</span><span class=\"p\">])</span> <span class=\"o\">*</span> \\</pre>\n",
       "<pre class='cython code score-0 '>          __pyx_t_16 = __pyx_v_iTest;\n",
       "          __pyx_t_17 = __pyx_v_idim;\n",
       "</pre><pre class=\"cython line score-0\" onclick='toggleDiv(this)'>+<span class=\"\">080</span>:                                               <span class=\"n\">kernel_mat</span><span class=\"p\">[</span><span class=\"n\">iTrain</span><span class=\"p\">,</span> <span class=\"n\">iTest</span><span class=\"p\">]</span></pre>\n",
       "<pre class='cython code score-0 '>          __pyx_t_18 = __pyx_v_iTrain;\n",
       "          __pyx_t_19 = __pyx_v_iTest;\n",
       "</pre><pre class=\"cython line score-0\">&#xA0;<span class=\"\">081</span>: </pre>\n",
       "<pre class=\"cython line score-0\">&#xA0;<span class=\"\">082</span>:     <span class=\"c\"># 2nd derivative</span></pre>\n",
       "<pre class=\"cython line score-0\" onclick='toggleDiv(this)'>+<span class=\"\">083</span>:     <span class=\"k\">elif</span> <span class=\"n\">n_derivative</span> <span class=\"o\">==</span> <span class=\"mf\">2</span><span class=\"p\">:</span></pre>\n",
       "<pre class='cython code score-0 '>    case 2:\n",
       "/* … */\n",
       "    break;\n",
       "    default:\n",
       "</pre><pre class=\"cython line score-0\">&#xA0;<span class=\"\">084</span>: </pre>\n",
       "<pre class=\"cython line score-0\">&#xA0;<span class=\"\">085</span>:         <span class=\"c\"># loop through dimensions</span></pre>\n",
       "<pre class=\"cython line score-0\" onclick='toggleDiv(this)'>+<span class=\"\">086</span>:         <span class=\"k\">for</span> <span class=\"n\">dim</span> <span class=\"ow\">in</span> <span class=\"nb\">range</span><span class=\"p\">(</span><span class=\"n\">d_dimensions</span><span class=\"p\">):</span></pre>\n",
       "<pre class='cython code score-0 '>    __pyx_t_7 = __pyx_v_d_dimensions;\n",
       "    for (__pyx_t_8 = 0; __pyx_t_8 &lt; __pyx_t_7; __pyx_t_8+=1) {\n",
       "      __pyx_v_dim = __pyx_t_8;\n",
       "</pre><pre class=\"cython line score-0\">&#xA0;<span class=\"\">087</span>: </pre>\n",
       "<pre class=\"cython line score-0\">&#xA0;<span class=\"\">088</span>:             <span class=\"c\"># loop through the number of test points</span></pre>\n",
       "<pre class=\"cython line score-0\" onclick='toggleDiv(this)'>+<span class=\"\">089</span>:             <span class=\"k\">for</span> <span class=\"n\">iTest</span> <span class=\"ow\">in</span> <span class=\"nb\">range</span><span class=\"p\">(</span><span class=\"n\">n_test</span><span class=\"p\">):</span></pre>\n",
       "<pre class='cython code score-0 '>      __pyx_t_9 = __pyx_v_n_test;\n",
       "      for (__pyx_t_10 = 0; __pyx_t_10 &lt; __pyx_t_9; __pyx_t_10+=1) {\n",
       "        __pyx_v_iTest = __pyx_t_10;\n",
       "</pre><pre class=\"cython line score-0\">&#xA0;<span class=\"\">090</span>: </pre>\n",
       "<pre class=\"cython line score-0\">&#xA0;<span class=\"\">091</span>:                 <span class=\"c\"># loop through the number of test points</span></pre>\n",
       "<pre class=\"cython line score-0\" onclick='toggleDiv(this)'>+<span class=\"\">092</span>:                 <span class=\"k\">for</span> <span class=\"n\">iTrain</span> <span class=\"ow\">in</span> <span class=\"nb\">range</span><span class=\"p\">(</span><span class=\"n\">n_train</span><span class=\"p\">):</span></pre>\n",
       "<pre class='cython code score-0 '>\n",
       "        /* \"_cython_magic_068b7d05edfe1c28296fa0d160e3f997.pyx\":92\n",
       " * \n",
       " *                 # loop through the number of test points\n",
       " *                 for iTrain in range(n_train):             # &lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;\n",
       " *                     derivative[iTest, dim] += weights[iTrain] * \\\n",
       " *                                               (theta ** 2 *\n",
       " */\n",
       "        __pyx_t_11 = __pyx_v_n_train;\n",
       "        for (__pyx_t_12 = 0; __pyx_t_12 &lt; __pyx_t_11; __pyx_t_12+=1) {\n",
       "          __pyx_v_iTrain = __pyx_t_12;\n",
       "</pre><pre class=\"cython line score-0\" onclick='toggleDiv(this)'>+<span class=\"\">093</span>:                     <span class=\"n\">derivative</span><span class=\"p\">[</span><span class=\"n\">iTest</span><span class=\"p\">,</span> <span class=\"n\">dim</span><span class=\"p\">]</span> <span class=\"o\">+=</span> <span class=\"n\">weights</span><span class=\"p\">[</span><span class=\"n\">iTrain</span><span class=\"p\">]</span> <span class=\"o\">*</span> \\</pre>\n",
       "<pre class='cython code score-0 '>          __pyx_t_22 = __pyx_v_iTrain;\n",
       "/* … */\n",
       "          __pyx_t_29 = __pyx_v_iTest;\n",
       "          __pyx_t_30 = __pyx_v_dim;\n",
       "          *((__pyx_t_5numpy_float64_t *) ( /* dim=1 */ (( /* dim=0 */ (__pyx_v_derivative.data + __pyx_t_29 * __pyx_v_derivative.strides[0]) ) + __pyx_t_30 * __pyx_v_derivative.strides[1]) )) += (((*((__pyx_t_5numpy_float64_t *) ( /* dim=0 */ (__pyx_v_weights.data + __pyx_t_22 * __pyx_v_weights.strides[0]) ))) * ((pow(__pyx_v_theta, 2.0) * pow(((*((__pyx_t_5numpy_float64_t *) ( /* dim=1 */ (( /* dim=0 */ (__pyx_v_x_train.data + __pyx_t_23 * __pyx_v_x_train.strides[0]) ) + __pyx_t_24 * __pyx_v_x_train.strides[1]) ))) - (*((__pyx_t_5numpy_float64_t *) ( /* dim=1 */ (( /* dim=0 */ (__pyx_v_x_function.data + __pyx_t_25 * __pyx_v_x_function.strides[0]) ) + __pyx_t_26 * __pyx_v_x_function.strides[1]) )))), 2.0)) - __pyx_v_theta)) * (*((__pyx_t_5numpy_float64_t *) ( /* dim=1 */ (( /* dim=0 */ (__pyx_v_kernel_mat.data + __pyx_t_27 * __pyx_v_kernel_mat.strides[0]) ) + __pyx_t_28 * __pyx_v_kernel_mat.strides[1]) ))));\n",
       "        }\n",
       "      }\n",
       "    }\n",
       "</pre><pre class=\"cython line score-0\">&#xA0;<span class=\"\">094</span>:                                               <span class=\"p\">(</span><span class=\"n\">theta</span> <span class=\"o\">**</span> <span class=\"mf\">2</span> <span class=\"o\">*</span></pre>\n",
       "<pre class=\"cython line score-0\" onclick='toggleDiv(this)'>+<span class=\"\">095</span>:                                                <span class=\"p\">(</span><span class=\"n\">x_train</span><span class=\"p\">[</span><span class=\"n\">iTrain</span><span class=\"p\">,</span> <span class=\"n\">dim</span><span class=\"p\">]</span> <span class=\"o\">-</span> <span class=\"n\">x_function</span><span class=\"p\">[</span><span class=\"n\">iTest</span><span class=\"p\">,</span> <span class=\"n\">dim</span><span class=\"p\">])</span> <span class=\"o\">**</span> <span class=\"mf\">2</span></pre>\n",
       "<pre class='cython code score-0 '>          __pyx_t_23 = __pyx_v_iTrain;\n",
       "          __pyx_t_24 = __pyx_v_dim;\n",
       "          __pyx_t_25 = __pyx_v_iTest;\n",
       "          __pyx_t_26 = __pyx_v_dim;\n",
       "</pre><pre class=\"cython line score-0\">&#xA0;<span class=\"\">096</span>:                                                <span class=\"o\">-</span> <span class=\"n\">theta</span><span class=\"p\">)</span> <span class=\"o\">*</span> \\</pre>\n",
       "<pre class=\"cython line score-0\" onclick='toggleDiv(this)'>+<span class=\"\">097</span>:                                               <span class=\"n\">kernel_mat</span><span class=\"p\">[</span><span class=\"n\">iTrain</span><span class=\"p\">,</span> <span class=\"n\">iTest</span><span class=\"p\">]</span></pre>\n",
       "<pre class='cython code score-0 '>          __pyx_t_27 = __pyx_v_iTrain;\n",
       "          __pyx_t_28 = __pyx_v_iTest;\n",
       "</pre><pre class=\"cython line score-0\">&#xA0;<span class=\"\">098</span>:     <span class=\"k\">else</span><span class=\"p\">:</span></pre>\n",
       "<pre class=\"cython line score-10\" onclick='toggleDiv(this)'>+<span class=\"\">099</span>:         <span class=\"k\">raise</span> <span class=\"ne\">ValueError</span><span class=\"p\">(</span><span class=\"s\">&#39;n_derivative should be equal to 1 or 2.&#39;</span><span class=\"p\">)</span></pre>\n",
       "<pre class='cython code score-10 '>    __pyx_t_1 = <span class='pyx_c_api'>__Pyx_PyObject_Call</span>(__pyx_builtin_ValueError, __pyx_tuple_, NULL);<span class='error_goto'> if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 99, __pyx_L1_error)</span>\n",
       "    <span class='refnanny'>__Pyx_GOTREF</span>(__pyx_t_1);\n",
       "    <span class='pyx_c_api'>__Pyx_Raise</span>(__pyx_t_1, 0, 0, 0);\n",
       "    <span class='pyx_macro_api'>__Pyx_DECREF</span>(__pyx_t_1); __pyx_t_1 = 0;\n",
       "    <span class='error_goto'>__PYX_ERR(0, 99, __pyx_L1_error)</span>\n",
       "    break;\n",
       "  }\n",
       "/* … */\n",
       "  __pyx_tuple_ = <span class='py_c_api'>PyTuple_Pack</span>(1, __pyx_kp_u_n_derivative_should_be_equal_to);<span class='error_goto'> if (unlikely(!__pyx_tuple_)) __PYX_ERR(0, 99, __pyx_L1_error)</span>\n",
       "  <span class='refnanny'>__Pyx_GOTREF</span>(__pyx_tuple_);\n",
       "  <span class='refnanny'>__Pyx_GIVEREF</span>(__pyx_tuple_);\n",
       "</pre><pre class=\"cython line score-0\">&#xA0;<span class=\"\">100</span>: </pre>\n",
       "<pre class=\"cython line score-45\" onclick='toggleDiv(this)'>+<span class=\"\">101</span>:     <span class=\"k\">return</span> <span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">asarray</span><span class=\"p\">(</span><span class=\"n\">derivative</span><span class=\"p\">)</span></pre>\n",
       "<pre class='cython code score-45 '>  <span class='pyx_macro_api'>__Pyx_XDECREF</span>(__pyx_r);\n",
       "  __pyx_t_3 = <span class='pyx_c_api'>__Pyx_GetModuleGlobalName</span>(__pyx_n_s_np);<span class='error_goto'> if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 101, __pyx_L1_error)</span>\n",
       "  <span class='refnanny'>__Pyx_GOTREF</span>(__pyx_t_3);\n",
       "  __pyx_t_2 = <span class='pyx_c_api'>__Pyx_PyObject_GetAttrStr</span>(__pyx_t_3, __pyx_n_s_asarray);<span class='error_goto'> if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 101, __pyx_L1_error)</span>\n",
       "  <span class='refnanny'>__Pyx_GOTREF</span>(__pyx_t_2);\n",
       "  <span class='pyx_macro_api'>__Pyx_DECREF</span>(__pyx_t_3); __pyx_t_3 = 0;\n",
       "  __pyx_t_3 = __pyx_memoryview_fromslice(__pyx_v_derivative, 2, (PyObject *(*)(char *)) __pyx_memview_get_nn___pyx_t_5numpy_float64_t, (int (*)(char *, PyObject *)) __pyx_memview_set_nn___pyx_t_5numpy_float64_t, 0);;<span class='error_goto'> if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 101, __pyx_L1_error)</span>\n",
       "  <span class='refnanny'>__Pyx_GOTREF</span>(__pyx_t_3);\n",
       "  __pyx_t_5 = NULL;\n",
       "  if (CYTHON_UNPACK_METHODS &amp;&amp; unlikely(<span class='py_c_api'>PyMethod_Check</span>(__pyx_t_2))) {\n",
       "    __pyx_t_5 = <span class='py_macro_api'>PyMethod_GET_SELF</span>(__pyx_t_2);\n",
       "    if (likely(__pyx_t_5)) {\n",
       "      PyObject* function = <span class='py_macro_api'>PyMethod_GET_FUNCTION</span>(__pyx_t_2);\n",
       "      <span class='pyx_macro_api'>__Pyx_INCREF</span>(__pyx_t_5);\n",
       "      <span class='pyx_macro_api'>__Pyx_INCREF</span>(function);\n",
       "      <span class='pyx_macro_api'>__Pyx_DECREF_SET</span>(__pyx_t_2, function);\n",
       "    }\n",
       "  }\n",
       "  if (!__pyx_t_5) {\n",
       "    __pyx_t_1 = <span class='pyx_c_api'>__Pyx_PyObject_CallOneArg</span>(__pyx_t_2, __pyx_t_3);<span class='error_goto'> if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 101, __pyx_L1_error)</span>\n",
       "    <span class='pyx_macro_api'>__Pyx_DECREF</span>(__pyx_t_3); __pyx_t_3 = 0;\n",
       "    <span class='refnanny'>__Pyx_GOTREF</span>(__pyx_t_1);\n",
       "  } else {\n",
       "    #if CYTHON_FAST_PYCALL\n",
       "    if (<span class='py_c_api'>PyFunction_Check</span>(__pyx_t_2)) {\n",
       "      PyObject *__pyx_temp[2] = {__pyx_t_5, __pyx_t_3};\n",
       "      __pyx_t_1 = <span class='pyx_c_api'>__Pyx_PyFunction_FastCall</span>(__pyx_t_2, __pyx_temp+1-1, 1+1);<span class='error_goto'> if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 101, __pyx_L1_error)</span>\n",
       "      <span class='pyx_macro_api'>__Pyx_XDECREF</span>(__pyx_t_5); __pyx_t_5 = 0;\n",
       "      <span class='refnanny'>__Pyx_GOTREF</span>(__pyx_t_1);\n",
       "      <span class='pyx_macro_api'>__Pyx_DECREF</span>(__pyx_t_3); __pyx_t_3 = 0;\n",
       "    } else\n",
       "    #endif\n",
       "    #if CYTHON_FAST_PYCCALL\n",
       "    if (<span class='pyx_c_api'>__Pyx_PyFastCFunction_Check</span>(__pyx_t_2)) {\n",
       "      PyObject *__pyx_temp[2] = {__pyx_t_5, __pyx_t_3};\n",
       "      __pyx_t_1 = <span class='pyx_c_api'>__Pyx_PyCFunction_FastCall</span>(__pyx_t_2, __pyx_temp+1-1, 1+1);<span class='error_goto'> if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 101, __pyx_L1_error)</span>\n",
       "      <span class='pyx_macro_api'>__Pyx_XDECREF</span>(__pyx_t_5); __pyx_t_5 = 0;\n",
       "      <span class='refnanny'>__Pyx_GOTREF</span>(__pyx_t_1);\n",
       "      <span class='pyx_macro_api'>__Pyx_DECREF</span>(__pyx_t_3); __pyx_t_3 = 0;\n",
       "    } else\n",
       "    #endif\n",
       "    {\n",
       "      __pyx_t_4 = <span class='py_c_api'>PyTuple_New</span>(1+1);<span class='error_goto'> if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 101, __pyx_L1_error)</span>\n",
       "      <span class='refnanny'>__Pyx_GOTREF</span>(__pyx_t_4);\n",
       "      <span class='refnanny'>__Pyx_GIVEREF</span>(__pyx_t_5); <span class='py_macro_api'>PyTuple_SET_ITEM</span>(__pyx_t_4, 0, __pyx_t_5); __pyx_t_5 = NULL;\n",
       "      <span class='refnanny'>__Pyx_GIVEREF</span>(__pyx_t_3);\n",
       "      <span class='py_macro_api'>PyTuple_SET_ITEM</span>(__pyx_t_4, 0+1, __pyx_t_3);\n",
       "      __pyx_t_3 = 0;\n",
       "      __pyx_t_1 = <span class='pyx_c_api'>__Pyx_PyObject_Call</span>(__pyx_t_2, __pyx_t_4, NULL);<span class='error_goto'> if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 101, __pyx_L1_error)</span>\n",
       "      <span class='refnanny'>__Pyx_GOTREF</span>(__pyx_t_1);\n",
       "      <span class='pyx_macro_api'>__Pyx_DECREF</span>(__pyx_t_4); __pyx_t_4 = 0;\n",
       "    }\n",
       "  }\n",
       "  <span class='pyx_macro_api'>__Pyx_DECREF</span>(__pyx_t_2); __pyx_t_2 = 0;\n",
       "  __pyx_r = __pyx_t_1;\n",
       "  __pyx_t_1 = 0;\n",
       "  goto __pyx_L0;\n",
       "</pre></div></body></html>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%cython -a\n",
    "\n",
    "cimport cython\n",
    "import numpy as np\n",
    "cimport numpy as np\n",
    "\n",
    "@cython.boundscheck(False)\n",
    "@cython.wraparound(False)\n",
    "def rbf_derivative_cython(np.float64_t[:, :] x_train, \n",
    "                   np.float64_t[:, :] x_function,\n",
    "                   np.float64_t[:] weights,\n",
    "                   np.float64_t[:, :] kernel_mat,\n",
    "                   np.int_t n_derivative,\n",
    "                   np.float64_t gamma):\n",
    "    \"\"\"This function calculates the rbf derivative using\n",
    "    Cython. It has been fairly optimized and provides x100\n",
    "    speedup over the original python function.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    x_train : array, [N x D], int64\n",
    "        The training data used to find the kernel model.\n",
    "\n",
    "    x_function  : array, [M x D], int64\n",
    "        The test points (or vector) to use.\n",
    "\n",
    "    weights   : array, [N x D], float64\n",
    "        The weights found from the kernel model\n",
    "            y = K * weights\n",
    "\n",
    "    kernel_mat: array, [N x M], float64\n",
    "        The rbf kernel matrix with the similarities between the test\n",
    "        points and the training points.\n",
    "\n",
    "    n_derivative : int, (default = 1) {1, 2}, int\n",
    "        chooses which nth derivative to calculate\n",
    "\n",
    "    gamma : float, default: None, float64\n",
    "        the parameter for the rbf_kernel matrix function\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "\n",
    "    derivative : array, [M x D]\n",
    "        returns the derivative with respect to training points used in\n",
    "        the kernel model and the test points.\n",
    "\n",
    "    Information\n",
    "    -----------\n",
    "    Author: Juan Emmanuel Johnson\n",
    "    Email : jej2744@rit.edu\n",
    "            juan.johnson@uv.es\n",
    "    \"\"\"\n",
    "    cdef int d_dimensions = x_function.shape[1]\n",
    "    cdef int n_test = x_function.shape[0]\n",
    "    cdef int n_train = x_train.shape[0]\n",
    "    cdef int idim, iTest, iTrain\n",
    "    \n",
    "    # initialize the derivative\n",
    "    cdef np.float64_t[:,:] derivative = np.zeros((n_test, d_dimensions))\n",
    "\n",
    "    # consolidate the parameters\n",
    "    cdef np.float64_t theta = 2.0 * gamma\n",
    "\n",
    "\n",
    "    if n_derivative == 1:\n",
    "        \n",
    "        # loop through dimensions\n",
    "        for idim in range(d_dimensions):\n",
    "\n",
    "            # loop through the number of test points\n",
    "            for iTest in range(n_test):\n",
    "\n",
    "                # loop through the number of test points\n",
    "                for iTrain in range(n_train):\n",
    "\n",
    "                    # calculate the derivative for the test points\n",
    "                    derivative[iTest, idim] += theta * weights[iTrain] * \\\n",
    "                                              (x_train[iTrain, idim] -\n",
    "                                               x_function[iTest, idim]) * \\\n",
    "                                              kernel_mat[iTrain, iTest]\n",
    "                        \n",
    "    # 2nd derivative\n",
    "    elif n_derivative == 2:\n",
    "\n",
    "        # loop through dimensions\n",
    "        for dim in range(d_dimensions):\n",
    "\n",
    "            # loop through the number of test points\n",
    "            for iTest in range(n_test):\n",
    "\n",
    "                # loop through the number of test points\n",
    "                for iTrain in range(n_train):\n",
    "                    derivative[iTest, dim] += weights[iTrain] * \\\n",
    "                                              (theta ** 2 *\n",
    "                                               (x_train[iTrain, dim] - x_function[iTest, dim]) ** 2\n",
    "                                               - theta) * \\\n",
    "                                              kernel_mat[iTrain, iTest] \n",
    "    else:\n",
    "        raise ValueError('n_derivative should be equal to 1 or 2.')\n",
    "                            \n",
    "    return np.asarray(derivative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "derivative_cython = rbf_derivative_cython(np.float64(x_train),\n",
    "                                          np.float64(x_test),\n",
    "                                          kernel_mat=kernel, \n",
    "                                          weights=weights.squeeze(), \n",
    "                                          n_derivative=n_derivative, \n",
    "                                          gamma=np.float64(gamma))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "float64\n",
      "float64\n"
     ]
    }
   ],
   "source": [
    "print(np.allclose(derivative, derivative_cython))\n",
    "print(derivative.dtype)\n",
    "print(derivative_cy.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cython:\n",
      "389 µs ± 25.4 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "print('Cython:')\n",
    "cython_speedup = %timeit -o rbf_derivative_cython(np.float64(x_train), np.float64(x_test), kernel_mat=kernel, weights=weights.squeeze(), n_derivative=n_derivative, gamma=gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pure Python:\n",
      "1.0\n",
      "Numba w/ Jit Speedup:\n",
      "1.0067572125699529\n",
      "Cython speedup:\n",
      "3772.616076209928\n"
     ]
    }
   ],
   "source": [
    "print('Pure Python:')\n",
    "print(original_python.best / original_python.best) \n",
    "\n",
    "print('Numba w/ Jit Speedup:')\n",
    "print(original_python.best / jit_speedup.best)\n",
    "\n",
    "print('Cython speedup:')\n",
    "print(original_python.best / cython_speedup.best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Without GIL Lock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Error compiling Cython file:\n",
      "------------------------------------------------------------\n",
      "...\n",
      "        \n",
      "        # loop through dimensions\n",
      "        for idim in prange(d_dimensions, nogil=True):\n",
      "\n",
      "            # loop through the number of test points\n",
      "            for iTest in prange(n_test, nogil=True):\n",
      "                              ^\n",
      "------------------------------------------------------------\n",
      "\n",
      "/Users/eman/.ipython/cython/_cython_magic_029e0f0e560b830aefa06c993b2d5ad8.pyx:72:31: Trying to release the GIL while it was previously released.\n",
      "\n",
      "Error compiling Cython file:\n",
      "------------------------------------------------------------\n",
      "...\n",
      "\n",
      "            # loop through the number of test points\n",
      "            for iTest in prange(n_test, nogil=True):\n",
      "\n",
      "                # loop through the number of test points\n",
      "                for iTrain in prange(n_train, nogil=True):\n",
      "                                   ^\n",
      "------------------------------------------------------------\n",
      "\n",
      "/Users/eman/.ipython/cython/_cython_magic_029e0f0e560b830aefa06c993b2d5ad8.pyx:75:36: Trying to release the GIL while it was previously released.\n",
      "\n",
      "Error compiling Cython file:\n",
      "------------------------------------------------------------\n",
      "...\n",
      "                        \n",
      "    # 2nd derivative\n",
      "    elif n_derivative == 2:\n",
      "\n",
      "        # loop through dimensions\n",
      "        for dim in prange(d_dimensions, nogil=True):\n",
      "               ^\n",
      "------------------------------------------------------------\n",
      "\n",
      "/Users/eman/.ipython/cython/_cython_magic_029e0f0e560b830aefa06c993b2d5ad8.pyx:87:16: target may not be a Python object as we don't have the GIL\n",
      "\n",
      "Error compiling Cython file:\n",
      "------------------------------------------------------------\n",
      "...\n",
      "\n",
      "        # loop through dimensions\n",
      "        for dim in prange(d_dimensions, nogil=True):\n",
      "\n",
      "            # loop through the number of test points\n",
      "            for iTest in prange(n_test, nogil=True):\n",
      "                              ^\n",
      "------------------------------------------------------------\n",
      "\n",
      "/Users/eman/.ipython/cython/_cython_magic_029e0f0e560b830aefa06c993b2d5ad8.pyx:90:31: Trying to release the GIL while it was previously released.\n",
      "\n",
      "Error compiling Cython file:\n",
      "------------------------------------------------------------\n",
      "...\n",
      "\n",
      "            # loop through the number of test points\n",
      "            for iTest in prange(n_test, nogil=True):\n",
      "\n",
      "                # loop through the number of test points\n",
      "                for iTrain in prange(n_train, nogil=True):\n",
      "                                   ^\n",
      "------------------------------------------------------------\n",
      "\n",
      "/Users/eman/.ipython/cython/_cython_magic_029e0f0e560b830aefa06c993b2d5ad8.pyx:93:36: Trying to release the GIL while it was previously released.\n",
      "\n",
      "Error compiling Cython file:\n",
      "------------------------------------------------------------\n",
      "...\n",
      "            # loop through the number of test points\n",
      "            for iTest in prange(n_test, nogil=True):\n",
      "\n",
      "                # loop through the number of test points\n",
      "                for iTrain in prange(n_train, nogil=True):\n",
      "                    derivative[iTest, dim] += weights[iTrain] * \\\n",
      "                                        ^\n",
      "------------------------------------------------------------\n",
      "\n",
      "/Users/eman/.ipython/cython/_cython_magic_029e0f0e560b830aefa06c993b2d5ad8.pyx:94:41: Coercion from Python not allowed without the GIL\n",
      "\n",
      "Error compiling Cython file:\n",
      "------------------------------------------------------------\n",
      "...\n",
      "\n",
      "                # loop through the number of test points\n",
      "                for iTrain in prange(n_train, nogil=True):\n",
      "                    derivative[iTest, dim] += weights[iTrain] * \\\n",
      "                                              (theta ** 2 *\n",
      "                                               (x_train[iTrain, dim] - x_function[iTest, dim]) ** 2\n",
      "                                                                  ^\n",
      "------------------------------------------------------------\n",
      "\n",
      "/Users/eman/.ipython/cython/_cython_magic_029e0f0e560b830aefa06c993b2d5ad8.pyx:96:67: Coercion from Python not allowed without the GIL\n",
      "\n",
      "Error compiling Cython file:\n",
      "------------------------------------------------------------\n",
      "...\n",
      "\n",
      "                # loop through the number of test points\n",
      "                for iTrain in prange(n_train, nogil=True):\n",
      "                    derivative[iTest, dim] += weights[iTrain] * \\\n",
      "                                              (theta ** 2 *\n",
      "                                               (x_train[iTrain, dim] - x_function[iTest, dim]) ** 2\n",
      "                                                                                           ^\n",
      "------------------------------------------------------------\n",
      "\n",
      "/Users/eman/.ipython/cython/_cython_magic_029e0f0e560b830aefa06c993b2d5ad8.pyx:96:92: Coercion from Python not allowed without the GIL\n"
     ]
    }
   ],
   "source": [
    "%%cython\n",
    "\n",
    "cimport cython\n",
    "import numpy as np\n",
    "cimport numpy as np\n",
    "from cython.parallel import prange\n",
    "\n",
    "@cython.boundscheck(False)\n",
    "@cython.wraparound(False)\n",
    "def rbf_derivative_cython(np.float64_t[:, :] x_train, \n",
    "                   np.float64_t[:, :] x_function,\n",
    "                   np.float64_t[:] weights,\n",
    "                   np.float64_t[:, :] kernel_mat,\n",
    "                   np.int_t n_derivative,\n",
    "                   np.float64_t gamma):\n",
    "    \"\"\"This function calculates the rbf derivative using\n",
    "    Cython. It has been fairly optimized and provides x100\n",
    "    speedup over the original python function.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    x_train : array, [N x D], int64\n",
    "        The training data used to find the kernel model.\n",
    "\n",
    "    x_function  : array, [M x D], int64\n",
    "        The test points (or vector) to use.\n",
    "\n",
    "    weights   : array, [N x D], float64\n",
    "        The weights found from the kernel model\n",
    "            y = K * weights\n",
    "\n",
    "    kernel_mat: array, [N x M], float64\n",
    "        The rbf kernel matrix with the similarities between the test\n",
    "        points and the training points.\n",
    "\n",
    "    n_derivative : int, (default = 1) {1, 2}, int\n",
    "        chooses which nth derivative to calculate\n",
    "\n",
    "    gamma : float, default: None, float64\n",
    "        the parameter for the rbf_kernel matrix function\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "\n",
    "    derivative : array, [M x D]\n",
    "        returns the derivative with respect to training points used in\n",
    "        the kernel model and the test points.\n",
    "\n",
    "    Information\n",
    "    -----------\n",
    "    Author: Juan Emmanuel Johnson\n",
    "    Email : jej2744@rit.edu\n",
    "            juan.johnson@uv.es\n",
    "    \"\"\"\n",
    "    cdef int d_dimensions = x_function.shape[1]\n",
    "    cdef int n_test = x_function.shape[0]\n",
    "    cdef int n_train = x_train.shape[0]\n",
    "    cdef int idim, iTest, iTrain\n",
    "    \n",
    "    # initialize the derivative\n",
    "    cdef np.float64_t[:,:] derivative = np.zeros((n_test, d_dimensions))\n",
    "\n",
    "    # consolidate the parameters\n",
    "    cdef np.float64_t theta = 2.0 * gamma\n",
    "\n",
    "\n",
    "    if n_derivative == 1:\n",
    "        \n",
    "        # loop through dimensions\n",
    "        for idim in prange(d_dimensions, nogil=True):\n",
    "\n",
    "            # loop through the number of test points\n",
    "            for iTest in prange(n_test, nogil=True):\n",
    "\n",
    "                # loop through the number of test points\n",
    "                for iTrain in prange(n_train, nogil=True):\n",
    "\n",
    "                    # calculate the derivative for the test points\n",
    "                    derivative[iTest, idim] += theta * weights[iTrain] * \\\n",
    "                                              (x_train[iTrain, idim] -\n",
    "                                               x_function[iTest, idim]) * \\\n",
    "                                              kernel_mat[iTrain, iTest]\n",
    "                        \n",
    "    # 2nd derivative\n",
    "    elif n_derivative == 2:\n",
    "\n",
    "        # loop through dimensions\n",
    "        for dim in prange(d_dimensions, nogil=True):\n",
    "\n",
    "            # loop through the number of test points\n",
    "            for iTest in prange(n_test, nogil=True):\n",
    "\n",
    "                # loop through the number of test points\n",
    "                for iTrain in prange(n_train, nogil=True):\n",
    "                    derivative[iTest, dim] += weights[iTrain] * \\\n",
    "                                              (theta ** 2 *\n",
    "                                               (x_train[iTrain, dim] - x_function[iTest, dim]) ** 2\n",
    "                                               - theta) * \\\n",
    "                                              kernel_mat[iTrain, iTest] \n",
    "    else:\n",
    "        raise ValueError('n_derivative should be equal to 1 or 2.')\n",
    "                            \n",
    "    return np.asarray(derivative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making Numba Faster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@jit\n",
    "def rbf_derivative_numba(x_train, x_function, weights, kernel_mat,\n",
    "                   n_derivative=1, gamma=1.0):\n",
    "    \"\"\"This function calculates the rbf derivative\n",
    "    Parameters\n",
    "    ----------\n",
    "    x_train : array, [N x D]\n",
    "        The training data used to find the kernel model.\n",
    "\n",
    "    x_function  : array, [M x D]\n",
    "        The test points (or vector) to use.\n",
    "\n",
    "    weights   : array, [N x D]\n",
    "        The weights found from the kernel model\n",
    "            y = K * weights\n",
    "\n",
    "    kernel_mat: array, [N x M], default: None\n",
    "        The rbf kernel matrix with the similarities between the test\n",
    "        points and the training points.\n",
    "\n",
    "    n_derivative : int, (default = 1) {1, 2}\n",
    "        chooses which nth derivative to calculate\n",
    "\n",
    "    gamma : float, default: None\n",
    "        the parameter for the rbf_kernel matrix function\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "\n",
    "    derivative : array, [M x D]\n",
    "        returns the derivative with respect to training points used in\n",
    "        the kernel model and the test points.\n",
    "\n",
    "    Information\n",
    "    -----------\n",
    "    Author: Juan Emmanuel Johnson\n",
    "    Email : jej2744@rit.edu\n",
    "            juan.johnson@uv.es\n",
    "    \"\"\"\n",
    "\n",
    "    # initialize the derivative\n",
    "    d_dimensions = x_function.shape[1]\n",
    "    n_test = x_function.shape[0]\n",
    "    n_train = x_train.shape[0]\n",
    "    \n",
    "    derivative = np.zeros((n_test, d_dimensions))\n",
    "\n",
    "    # consolidate the parameters\n",
    "    theta = 2.0 * gamma\n",
    "\n",
    "\n",
    "    if n_derivative == 1:\n",
    "        \n",
    "        # loop through dimensions\n",
    "        for idim in np.arange(0, d_dimensions):\n",
    "\n",
    "            # loop through the number of test points\n",
    "            for iTest in np.arange(0, n_test):\n",
    "\n",
    "                # loop through the number of test points\n",
    "                for iTrain in np.arange(0, n_train):\n",
    "\n",
    "                    # calculate the derivative for the test points\n",
    "                    derivative[iTest, idim] += theta * weights[iTrain] * \\\n",
    "                                              (x_train[iTrain, idim] -\n",
    "                                               x_function[iTest, idim]) * \\\n",
    "                                              kernel_mat[iTrain, iTest]\n",
    "                        \n",
    "    # 2nd derivative\n",
    "    elif n_derivative == 2:\n",
    "\n",
    "        # loop through dimensions\n",
    "        for dim in np.arange(0, d_dimensions):\n",
    "\n",
    "            # loop through the number of test points\n",
    "            for iTest in np.arange(0, n_test):\n",
    "\n",
    "                # loop through the number of test points\n",
    "                for iTrain in np.arange(0, n_train):\n",
    "                    derivative[iTest, dim] += weights[iTrain] * \\\n",
    "                                              (theta ** 2 *\n",
    "                                               (x_train[iTrain, dim] - x_function[iTest, dim]) ** 2\n",
    "                                               - theta) * \\\n",
    "                                              kernel_mat[iTrain, iTest]\n",
    "\n",
    "    return derivative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "temp_d = rbf_derivative_numba(np.int64(x_train), \n",
    "                              np.int64(x_test), \n",
    "                              kernel_mat=np.float64(kernel), \n",
    "                              weights=np.float64(weights),\n",
    "                              n_derivative=n_derivative,\n",
    "                              gamma=gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.39 s ± 50.3 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "rbf_derivative_numba(np.int64(x_train), \n",
    "                              np.int64(x_test), \n",
    "                              kernel_mat=np.float64(kernel), \n",
    "                              weights=np.float64(weights),\n",
    "                              n_derivative=n_derivative,\n",
    "                              gamma=gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rbf_derivative_numba (array(int64, 2d, C), array(int64, 2d, C), array(float64, 2d, C), array(float64, 2d, C), int64, float64)\n",
      "--------------------------------------------------------------------------------\n",
      "# File: <ipython-input-138-76c90ea42936>\n",
      "# --- LINE 1 --- \n",
      "# label 0\n",
      "#   del $const0.3\n",
      "#   del $0.2\n",
      "#   del $0.4\n",
      "#   del $const0.7\n",
      "#   del $0.6\n",
      "#   del $0.8\n",
      "#   del $const0.11\n",
      "#   del $0.10\n",
      "#   del $0.12\n",
      "#   del $0.13\n",
      "#   del $0.17\n",
      "#   del $0.14\n",
      "#   del $0.18\n",
      "#   del gamma\n",
      "#   del $const0.19\n",
      "#   del $0.21\n",
      "#   del $const0.23\n",
      "\n",
      "@jit\n",
      "\n",
      "# --- LINE 2 --- \n",
      "\n",
      "def rbf_derivative_numba(x_train, x_function, weights, kernel_mat,\n",
      "\n",
      "                   # --- LINE 3 --- \n",
      "\n",
      "                   n_derivative=1, gamma=1.0):\n",
      "\n",
      "    # --- LINE 4 --- \n",
      "\n",
      "    \"\"\"This function calculates the rbf derivative\n",
      "\n",
      "    # --- LINE 5 --- \n",
      "\n",
      "    Parameters\n",
      "\n",
      "    # --- LINE 6 --- \n",
      "\n",
      "    ----------\n",
      "\n",
      "    # --- LINE 7 --- \n",
      "\n",
      "    x_train : array, [N x D]\n",
      "\n",
      "        # --- LINE 8 --- \n",
      "\n",
      "        The training data used to find the kernel model.\n",
      "\n",
      "# --- LINE 9 --- \n",
      "\n",
      "\n",
      "\n",
      "    # --- LINE 10 --- \n",
      "\n",
      "    x_function  : array, [M x D]\n",
      "\n",
      "        # --- LINE 11 --- \n",
      "\n",
      "        The test points (or vector) to use.\n",
      "\n",
      "# --- LINE 12 --- \n",
      "\n",
      "\n",
      "\n",
      "    # --- LINE 13 --- \n",
      "\n",
      "    weights   : array, [N x D]\n",
      "\n",
      "        # --- LINE 14 --- \n",
      "\n",
      "        The weights found from the kernel model\n",
      "\n",
      "            # --- LINE 15 --- \n",
      "\n",
      "            y = K * weights\n",
      "\n",
      "# --- LINE 16 --- \n",
      "\n",
      "\n",
      "\n",
      "    # --- LINE 17 --- \n",
      "\n",
      "    kernel_mat: array, [N x M], default: None\n",
      "\n",
      "        # --- LINE 18 --- \n",
      "\n",
      "        The rbf kernel matrix with the similarities between the test\n",
      "\n",
      "        # --- LINE 19 --- \n",
      "\n",
      "        points and the training points.\n",
      "\n",
      "# --- LINE 20 --- \n",
      "\n",
      "\n",
      "\n",
      "    # --- LINE 21 --- \n",
      "\n",
      "    n_derivative : int, (default = 1) {1, 2}\n",
      "\n",
      "        # --- LINE 22 --- \n",
      "\n",
      "        chooses which nth derivative to calculate\n",
      "\n",
      "# --- LINE 23 --- \n",
      "\n",
      "\n",
      "\n",
      "    # --- LINE 24 --- \n",
      "\n",
      "    gamma : float, default: None\n",
      "\n",
      "        # --- LINE 25 --- \n",
      "\n",
      "        the parameter for the rbf_kernel matrix function\n",
      "\n",
      "# --- LINE 26 --- \n",
      "\n",
      "\n",
      "\n",
      "    # --- LINE 27 --- \n",
      "\n",
      "    Returns\n",
      "\n",
      "    # --- LINE 28 --- \n",
      "\n",
      "    -------\n",
      "\n",
      "# --- LINE 29 --- \n",
      "\n",
      "\n",
      "\n",
      "    # --- LINE 30 --- \n",
      "\n",
      "    derivative : array, [M x D]\n",
      "\n",
      "        # --- LINE 31 --- \n",
      "\n",
      "        returns the derivative with respect to training points used in\n",
      "\n",
      "        # --- LINE 32 --- \n",
      "\n",
      "        the kernel model and the test points.\n",
      "\n",
      "# --- LINE 33 --- \n",
      "\n",
      "\n",
      "\n",
      "    # --- LINE 34 --- \n",
      "\n",
      "    Information\n",
      "\n",
      "    # --- LINE 35 --- \n",
      "\n",
      "    -----------\n",
      "\n",
      "    # --- LINE 36 --- \n",
      "\n",
      "    Author: Juan Emmanuel Johnson\n",
      "\n",
      "    # --- LINE 37 --- \n",
      "\n",
      "    Email : jej2744@rit.edu\n",
      "\n",
      "            # --- LINE 38 --- \n",
      "\n",
      "            juan.johnson@uv.es\n",
      "\n",
      "    # --- LINE 39 --- \n",
      "\n",
      "    \"\"\"\n",
      "\n",
      "# --- LINE 40 --- \n",
      "\n",
      "\n",
      "\n",
      "    # --- LINE 41 --- \n",
      "\n",
      "    # initialize the derivative\n",
      "\n",
      "    # --- LINE 42 --- \n",
      "    #   x_train = arg(0, name=x_train)  :: pyobject\n",
      "    #   x_function = arg(1, name=x_function)  :: pyobject\n",
      "    #   weights = arg(2, name=weights)  :: pyobject\n",
      "    #   kernel_mat = arg(3, name=kernel_mat)  :: pyobject\n",
      "    #   n_derivative = arg(4, name=n_derivative)  :: pyobject\n",
      "    #   gamma = arg(5, name=gamma)  :: pyobject\n",
      "    #   $0.2 = getattr(value=x_function, attr=shape)  :: pyobject\n",
      "    #   $const0.3 = const(int, 1)  :: pyobject\n",
      "    #   $0.4 = getitem(value=$0.2, index=$const0.3)  :: pyobject\n",
      "    #   d_dimensions = $0.4  :: pyobject\n",
      "\n",
      "    d_dimensions = x_function.shape[1]\n",
      "\n",
      "    # --- LINE 43 --- \n",
      "    #   $0.6 = getattr(value=x_function, attr=shape)  :: pyobject\n",
      "    #   $const0.7 = const(int, 0)  :: pyobject\n",
      "    #   $0.8 = getitem(value=$0.6, index=$const0.7)  :: pyobject\n",
      "    #   n_test = $0.8  :: pyobject\n",
      "\n",
      "    n_test = x_function.shape[0]\n",
      "\n",
      "    # --- LINE 44 --- \n",
      "    #   $0.10 = getattr(value=x_train, attr=shape)  :: pyobject\n",
      "    #   $const0.11 = const(int, 0)  :: pyobject\n",
      "    #   $0.12 = getitem(value=$0.10, index=$const0.11)  :: pyobject\n",
      "    #   n_train = $0.12  :: pyobject\n",
      "\n",
      "    n_train = x_train.shape[0]\n",
      "\n",
      "# --- LINE 45 --- \n",
      "\n",
      "\n",
      "\n",
      "    # --- LINE 46 --- \n",
      "    #   $0.13 = global(np: <module 'numpy' from '/Users/eman/anaconda3/lib/python3.6/site-packages/numpy/__init__.py'>)  :: pyobject\n",
      "    #   $0.14 = getattr(value=$0.13, attr=zeros)  :: pyobject\n",
      "    #   $0.17 = build_tuple(items=[Var(n_test, <ipython-input-138-76c90ea42936> (43)), Var(d_dimensions, <ipython-input-138-76c90ea42936> (42))])  :: pyobject\n",
      "    #   $0.18 = call $0.14($0.17, func=$0.14, args=[Var($0.17, <ipython-input-138-76c90ea42936> (46))], kws=(), vararg=None)  :: pyobject\n",
      "    #   derivative = $0.18  :: pyobject\n",
      "\n",
      "    derivative = np.zeros((n_test, d_dimensions))\n",
      "\n",
      "# --- LINE 47 --- \n",
      "\n",
      "\n",
      "\n",
      "    # --- LINE 48 --- \n",
      "\n",
      "    # consolidate the parameters\n",
      "\n",
      "    # --- LINE 49 --- \n",
      "    #   $const0.19 = const(float, 2.0)  :: pyobject\n",
      "    #   $0.21 = $const0.19 * gamma  :: pyobject\n",
      "    #   theta = $0.21  :: pyobject\n",
      "\n",
      "    theta = 2.0 * gamma\n",
      "\n",
      "# --- LINE 50 --- \n",
      "\n",
      "\n",
      "\n",
      "# --- LINE 51 --- \n",
      "\n",
      "\n",
      "\n",
      "    # --- LINE 52 --- \n",
      "    #   $const0.23 = const(int, 1)  :: pyobject\n",
      "    #   $0.24 = n_derivative == $const0.23  :: pyobject\n",
      "    #   branch $0.24, 60, 192\n",
      "    # label 60\n",
      "    #   del n_derivative\n",
      "    #   del $0.24\n",
      "\n",
      "    if n_derivative == 1:\n",
      "\n",
      "# --- LINE 53 --- \n",
      "\n",
      "\n",
      "\n",
      "        # --- LINE 54 --- \n",
      "\n",
      "        # loop through dimensions\n",
      "\n",
      "        # --- LINE 55 --- \n",
      "        #   jump 62\n",
      "        # label 62\n",
      "        #   $194 = const(LiftedLoop, LiftedLoop(<function rbf_derivative_numba at 0x1217b5950>))  :: XXX Lifted Loop XXX\n",
      "        #   $195 = call $194(d_dimensions, derivative, kernel_mat, n_test, n_train, theta, weights, x_function, x_train, func=$194, args=[Var(d_dimensions, <ipython-input-138-76c90ea42936> (42)), Var(derivative, <ipython-input-138-76c90ea42936> (46)), Var(kernel_mat, <ipython-input-138-76c90ea42936> (42)), Var(n_test, <ipython-input-138-76c90ea42936> (43)), Var(n_train, <ipython-input-138-76c90ea42936> (44)), Var(theta, <ipython-input-138-76c90ea42936> (49)), Var(weights, <ipython-input-138-76c90ea42936> (42)), Var(x_function, <ipython-input-138-76c90ea42936> (42)), Var(x_train, <ipython-input-138-76c90ea42936> (42))], kws=(), vararg=None)  :: XXX Lifted Loop XXX\n",
      "        #   del x_train\n",
      "        #   del x_function\n",
      "        #   del weights\n",
      "        #   del theta\n",
      "        #   del n_train\n",
      "        #   del n_test\n",
      "        #   del kernel_mat\n",
      "        #   del d_dimensions\n",
      "        #   del $194\n",
      "        #   derivative = static_getitem(value=$195, index=0, index_var=None)  :: pyobject\n",
      "        #   del $195\n",
      "        #   jump 190\n",
      "\n",
      "        for idim in np.arange(0, d_dimensions):\n",
      "\n",
      "# --- LINE 56 --- \n",
      "\n",
      "\n",
      "\n",
      "            # --- LINE 57 --- \n",
      "\n",
      "            # loop through the number of test points\n",
      "\n",
      "            # --- LINE 58 --- \n",
      "\n",
      "            for iTest in np.arange(0, n_test):\n",
      "\n",
      "# --- LINE 59 --- \n",
      "\n",
      "\n",
      "\n",
      "                # --- LINE 60 --- \n",
      "\n",
      "                # loop through the number of test points\n",
      "\n",
      "                # --- LINE 61 --- \n",
      "\n",
      "                for iTrain in np.arange(0, n_train):\n",
      "\n",
      "# --- LINE 62 --- \n",
      "\n",
      "\n",
      "\n",
      "                    # --- LINE 63 --- \n",
      "\n",
      "                    # calculate the derivative for the test points\n",
      "\n",
      "                    # --- LINE 64 --- \n",
      "\n",
      "                    derivative[iTest, idim] += theta * weights[iTrain] *                                               (x_train[iTrain, idim] -\n",
      "\n",
      "                                               # --- LINE 65 --- \n",
      "\n",
      "                                               x_function[iTest, idim]) * \\\n",
      "\n",
      "                                              # --- LINE 66 --- \n",
      "                                              # label 190\n",
      "                                              #   jump 344\n",
      "                                              # label 192\n",
      "                                              #   del $0.24\n",
      "                                              #   del n_derivative\n",
      "                                              #   del $const192.2\n",
      "\n",
      "                                              kernel_mat[iTrain, iTest]\n",
      "\n",
      "# --- LINE 67 --- \n",
      "\n",
      "\n",
      "\n",
      "    # --- LINE 68 --- \n",
      "\n",
      "    # 2nd derivative\n",
      "\n",
      "    # --- LINE 69 --- \n",
      "    #   $const192.2 = const(int, 2)  :: pyobject\n",
      "    #   $192.3 = n_derivative == $const192.2  :: pyobject\n",
      "    #   branch $192.3, 202, 344\n",
      "    # label 202\n",
      "    #   del $192.3\n",
      "\n",
      "    elif n_derivative == 2:\n",
      "\n",
      "# --- LINE 70 --- \n",
      "\n",
      "\n",
      "\n",
      "        # --- LINE 71 --- \n",
      "\n",
      "        # loop through dimensions\n",
      "\n",
      "        # --- LINE 72 --- \n",
      "        #   jump 204\n",
      "        # label 204\n",
      "        #   $191 = const(LiftedLoop, LiftedLoop(<function rbf_derivative_numba at 0x1217b5950>))  :: XXX Lifted Loop XXX\n",
      "        #   $192 = call $191(d_dimensions, derivative, kernel_mat, n_test, n_train, theta, weights, x_function, x_train, func=$191, args=[Var(d_dimensions, <ipython-input-138-76c90ea42936> (42)), Var(derivative, <ipython-input-138-76c90ea42936> (46)), Var(kernel_mat, <ipython-input-138-76c90ea42936> (42)), Var(n_test, <ipython-input-138-76c90ea42936> (43)), Var(n_train, <ipython-input-138-76c90ea42936> (44)), Var(theta, <ipython-input-138-76c90ea42936> (49)), Var(weights, <ipython-input-138-76c90ea42936> (42)), Var(x_function, <ipython-input-138-76c90ea42936> (42)), Var(x_train, <ipython-input-138-76c90ea42936> (42))], kws=(), vararg=None)  :: XXX Lifted Loop XXX\n",
      "        #   del x_train\n",
      "        #   del x_function\n",
      "        #   del weights\n",
      "        #   del theta\n",
      "        #   del n_train\n",
      "        #   del n_test\n",
      "        #   del kernel_mat\n",
      "        #   del d_dimensions\n",
      "        #   del $191\n",
      "        #   derivative = static_getitem(value=$192, index=0, index_var=None)  :: pyobject\n",
      "        #   del $192\n",
      "        #   jump 344\n",
      "\n",
      "        for dim in np.arange(0, d_dimensions):\n",
      "\n",
      "# --- LINE 73 --- \n",
      "\n",
      "\n",
      "\n",
      "            # --- LINE 74 --- \n",
      "\n",
      "            # loop through the number of test points\n",
      "\n",
      "            # --- LINE 75 --- \n",
      "\n",
      "            for iTest in np.arange(0, n_test):\n",
      "\n",
      "# --- LINE 76 --- \n",
      "\n",
      "\n",
      "\n",
      "                # --- LINE 77 --- \n",
      "\n",
      "                # loop through the number of test points\n",
      "\n",
      "                # --- LINE 78 --- \n",
      "\n",
      "                for iTrain in np.arange(0, n_train):\n",
      "\n",
      "                    # --- LINE 79 --- \n",
      "\n",
      "                    derivative[iTest, dim] += weights[iTrain] *                                               (theta ** 2 *\n",
      "\n",
      "                                               # --- LINE 80 --- \n",
      "\n",
      "                                               (x_train[iTrain, dim] - x_function[iTest, dim]) ** 2\n",
      "\n",
      "                                               # --- LINE 81 --- \n",
      "\n",
      "                                               - theta) * \\\n",
      "\n",
      "                                              # --- LINE 82 --- \n",
      "                                              # label 344\n",
      "                                              #   del x_train\n",
      "                                              #   del x_function\n",
      "                                              #   del weights\n",
      "                                              #   del theta\n",
      "                                              #   del n_train\n",
      "                                              #   del n_test\n",
      "                                              #   del kernel_mat\n",
      "                                              #   del d_dimensions\n",
      "                                              #   del $192.3\n",
      "                                              #   del derivative\n",
      "\n",
      "                                              kernel_mat[iTrain, iTest]\n",
      "\n",
      "# --- LINE 83 --- \n",
      "\n",
      "\n",
      "\n",
      "    # --- LINE 84 --- \n",
      "    #   $344.2 = cast(value=derivative)  :: pyobject\n",
      "    #   return $344.2\n",
      "\n",
      "    return derivative\n",
      "\n",
      "# The function contains lifted loops\n",
      "# Loop at line 72\n",
      "# Has 0 overloads\n",
      "# Loop at line 55\n",
      "# Has 1 overloads\n",
      "# File: <ipython-input-138-76c90ea42936>\n",
      "# --- LINE 1 --- \n",
      "\n",
      "@jit\n",
      "\n",
      "# --- LINE 2 --- \n",
      "\n",
      "def rbf_derivative_numba(x_train, x_function, weights, kernel_mat,\n",
      "\n",
      "                   # --- LINE 3 --- \n",
      "\n",
      "                   n_derivative=1, gamma=1.0):\n",
      "\n",
      "    # --- LINE 4 --- \n",
      "\n",
      "    \"\"\"This function calculates the rbf derivative\n",
      "\n",
      "    # --- LINE 5 --- \n",
      "\n",
      "    Parameters\n",
      "\n",
      "    # --- LINE 6 --- \n",
      "\n",
      "    ----------\n",
      "\n",
      "    # --- LINE 7 --- \n",
      "\n",
      "    x_train : array, [N x D]\n",
      "\n",
      "        # --- LINE 8 --- \n",
      "\n",
      "        The training data used to find the kernel model.\n",
      "\n",
      "# --- LINE 9 --- \n",
      "\n",
      "\n",
      "\n",
      "    # --- LINE 10 --- \n",
      "\n",
      "    x_function  : array, [M x D]\n",
      "\n",
      "        # --- LINE 11 --- \n",
      "\n",
      "        The test points (or vector) to use.\n",
      "\n",
      "# --- LINE 12 --- \n",
      "\n",
      "\n",
      "\n",
      "    # --- LINE 13 --- \n",
      "\n",
      "    weights   : array, [N x D]\n",
      "\n",
      "        # --- LINE 14 --- \n",
      "\n",
      "        The weights found from the kernel model\n",
      "\n",
      "            # --- LINE 15 --- \n",
      "\n",
      "            y = K * weights\n",
      "\n",
      "# --- LINE 16 --- \n",
      "\n",
      "\n",
      "\n",
      "    # --- LINE 17 --- \n",
      "\n",
      "    kernel_mat: array, [N x M], default: None\n",
      "\n",
      "        # --- LINE 18 --- \n",
      "\n",
      "        The rbf kernel matrix with the similarities between the test\n",
      "\n",
      "        # --- LINE 19 --- \n",
      "\n",
      "        points and the training points.\n",
      "\n",
      "# --- LINE 20 --- \n",
      "\n",
      "\n",
      "\n",
      "    # --- LINE 21 --- \n",
      "\n",
      "    n_derivative : int, (default = 1) {1, 2}\n",
      "\n",
      "        # --- LINE 22 --- \n",
      "\n",
      "        chooses which nth derivative to calculate\n",
      "\n",
      "# --- LINE 23 --- \n",
      "\n",
      "\n",
      "\n",
      "    # --- LINE 24 --- \n",
      "\n",
      "    gamma : float, default: None\n",
      "\n",
      "        # --- LINE 25 --- \n",
      "\n",
      "        the parameter for the rbf_kernel matrix function\n",
      "\n",
      "# --- LINE 26 --- \n",
      "\n",
      "\n",
      "\n",
      "    # --- LINE 27 --- \n",
      "\n",
      "    Returns\n",
      "\n",
      "    # --- LINE 28 --- \n",
      "\n",
      "    -------\n",
      "\n",
      "# --- LINE 29 --- \n",
      "\n",
      "\n",
      "\n",
      "    # --- LINE 30 --- \n",
      "\n",
      "    derivative : array, [M x D]\n",
      "\n",
      "        # --- LINE 31 --- \n",
      "\n",
      "        returns the derivative with respect to training points used in\n",
      "\n",
      "        # --- LINE 32 --- \n",
      "\n",
      "        the kernel model and the test points.\n",
      "\n",
      "# --- LINE 33 --- \n",
      "\n",
      "\n",
      "\n",
      "    # --- LINE 34 --- \n",
      "\n",
      "    Information\n",
      "\n",
      "    # --- LINE 35 --- \n",
      "\n",
      "    -----------\n",
      "\n",
      "    # --- LINE 36 --- \n",
      "\n",
      "    Author: Juan Emmanuel Johnson\n",
      "\n",
      "    # --- LINE 37 --- \n",
      "\n",
      "    Email : jej2744@rit.edu\n",
      "\n",
      "            # --- LINE 38 --- \n",
      "\n",
      "            juan.johnson@uv.es\n",
      "\n",
      "    # --- LINE 39 --- \n",
      "\n",
      "    \"\"\"\n",
      "\n",
      "# --- LINE 40 --- \n",
      "\n",
      "\n",
      "\n",
      "    # --- LINE 41 --- \n",
      "\n",
      "    # initialize the derivative\n",
      "\n",
      "    # --- LINE 42 --- \n",
      "\n",
      "    d_dimensions = x_function.shape[1]\n",
      "\n",
      "    # --- LINE 43 --- \n",
      "\n",
      "    n_test = x_function.shape[0]\n",
      "\n",
      "    # --- LINE 44 --- \n",
      "\n",
      "    n_train = x_train.shape[0]\n",
      "\n",
      "# --- LINE 45 --- \n",
      "\n",
      "\n",
      "\n",
      "    # --- LINE 46 --- \n",
      "\n",
      "    derivative = np.zeros((n_test, d_dimensions))\n",
      "\n",
      "# --- LINE 47 --- \n",
      "\n",
      "\n",
      "\n",
      "    # --- LINE 48 --- \n",
      "\n",
      "    # consolidate the parameters\n",
      "\n",
      "    # --- LINE 49 --- \n",
      "\n",
      "    theta = 2.0 * gamma\n",
      "\n",
      "# --- LINE 50 --- \n",
      "\n",
      "\n",
      "\n",
      "# --- LINE 51 --- \n",
      "\n",
      "\n",
      "\n",
      "    # --- LINE 52 --- \n",
      "\n",
      "    if n_derivative == 1:\n",
      "\n",
      "# --- LINE 53 --- \n",
      "\n",
      "\n",
      "\n",
      "        # --- LINE 54 --- \n",
      "\n",
      "        # loop through dimensions\n",
      "\n",
      "        # --- LINE 55 --- \n",
      "        # label 61\n",
      "        #   d_dimensions = arg(0, name=d_dimensions)  :: pyobject\n",
      "        #   derivative = arg(1, name=derivative)  :: pyobject\n",
      "        #   kernel_mat = arg(2, name=kernel_mat)  :: pyobject\n",
      "        #   n_test = arg(3, name=n_test)  :: pyobject\n",
      "        #   n_train = arg(4, name=n_train)  :: pyobject\n",
      "        #   theta = arg(5, name=theta)  :: pyobject\n",
      "        #   weights = arg(6, name=weights)  :: pyobject\n",
      "        #   x_function = arg(7, name=x_function)  :: pyobject\n",
      "        #   x_train = arg(8, name=x_train)  :: pyobject\n",
      "        #   jump 62\n",
      "        # label 62\n",
      "        #   $62.1 = global(np: <module 'numpy' from '/Users/eman/anaconda3/lib/python3.6/site-packages/numpy/__init__.py'>)  :: pyobject\n",
      "        #   $62.2 = getattr(value=$62.1, attr=arange)  :: pyobject\n",
      "        #   del $62.1\n",
      "        #   $const62.3 = const(int, 0)  :: pyobject\n",
      "        #   $62.5 = call $62.2($const62.3, d_dimensions, func=$62.2, args=[Var($const62.3, <ipython-input-138-76c90ea42936> (55)), Var(d_dimensions, <ipython-input-138-76c90ea42936> (42))], kws=(), vararg=None)  :: pyobject\n",
      "        #   del d_dimensions\n",
      "        #   del $const62.3\n",
      "        #   del $62.2\n",
      "        #   $62.6 = getiter(value=$62.5)  :: pyobject\n",
      "        #   del $62.5\n",
      "        #   $phi74.1 = $62.6  :: pyobject\n",
      "        #   del $62.6\n",
      "        #   jump 74\n",
      "        # label 74\n",
      "        #   $74.2 = iternext(value=$phi74.1)  :: pyobject\n",
      "        #   $74.3 = pair_first(value=$74.2)  :: pyobject\n",
      "        #   $74.4 = pair_second(value=$74.2)  :: pyobject\n",
      "        #   del $74.2\n",
      "        #   $phi76.1 = $74.3  :: pyobject\n",
      "        #   $phi188.1 = $74.3  :: pyobject\n",
      "        #   del $phi188.1\n",
      "        #   del $74.3\n",
      "        #   $phi188.2 = $phi74.1  :: pyobject\n",
      "        #   del $phi188.2\n",
      "        #   branch $74.4, 76, 188\n",
      "        # label 76\n",
      "        #   del $74.4\n",
      "        #   idim = $phi76.1  :: pyobject\n",
      "        #   del $phi76.1\n",
      "        #   jump 78\n",
      "        # label 78\n",
      "        # label 190\n",
      "        #   $193 = build_tuple(items=[Var(derivative, <ipython-input-138-76c90ea42936> (46))])  :: pyobject\n",
      "        #   del derivative\n",
      "        #   return $193\n",
      "\n",
      "        for idim in np.arange(0, d_dimensions):\n",
      "\n",
      "# --- LINE 56 --- \n",
      "\n",
      "\n",
      "\n",
      "            # --- LINE 57 --- \n",
      "\n",
      "            # loop through the number of test points\n",
      "\n",
      "            # --- LINE 58 --- \n",
      "            #   jump 80\n",
      "            # label 80\n",
      "            #   $80.1 = global(np: <module 'numpy' from '/Users/eman/anaconda3/lib/python3.6/site-packages/numpy/__init__.py'>)  :: pyobject\n",
      "            #   $80.2 = getattr(value=$80.1, attr=arange)  :: pyobject\n",
      "            #   del $80.1\n",
      "            #   $const80.3 = const(int, 0)  :: pyobject\n",
      "            #   $80.5 = call $80.2($const80.3, n_test, func=$80.2, args=[Var($const80.3, <ipython-input-138-76c90ea42936> (58)), Var(n_test, <ipython-input-138-76c90ea42936> (43))], kws=(), vararg=None)  :: pyobject\n",
      "            #   del $const80.3\n",
      "            #   del $80.2\n",
      "            #   $80.6 = getiter(value=$80.5)  :: pyobject\n",
      "            #   del $80.5\n",
      "            #   $phi92.1 = $80.6  :: pyobject\n",
      "            #   del $80.6\n",
      "            #   jump 92\n",
      "            # label 92\n",
      "            #   $92.2 = iternext(value=$phi92.1)  :: pyobject\n",
      "            #   $92.3 = pair_first(value=$92.2)  :: pyobject\n",
      "            #   $92.4 = pair_second(value=$92.2)  :: pyobject\n",
      "            #   del $92.2\n",
      "            #   $phi94.1 = $92.3  :: pyobject\n",
      "            #   $phi184.1 = $92.3  :: pyobject\n",
      "            #   del $phi184.1\n",
      "            #   del $92.3\n",
      "            #   $phi184.2 = $phi92.1  :: pyobject\n",
      "            #   del $phi184.2\n",
      "            #   branch $92.4, 94, 184\n",
      "            # label 94\n",
      "            #   del $92.4\n",
      "            #   iTest = $phi94.1  :: pyobject\n",
      "            #   del $phi94.1\n",
      "            #   jump 96\n",
      "            # label 96\n",
      "\n",
      "            for iTest in np.arange(0, n_test):\n",
      "\n",
      "# --- LINE 59 --- \n",
      "\n",
      "\n",
      "\n",
      "                # --- LINE 60 --- \n",
      "\n",
      "                # loop through the number of test points\n",
      "\n",
      "                # --- LINE 61 --- \n",
      "                #   jump 98\n",
      "                # label 98\n",
      "                #   $98.1 = global(np: <module 'numpy' from '/Users/eman/anaconda3/lib/python3.6/site-packages/numpy/__init__.py'>)  :: pyobject\n",
      "                #   $98.2 = getattr(value=$98.1, attr=arange)  :: pyobject\n",
      "                #   del $98.1\n",
      "                #   $const98.3 = const(int, 0)  :: pyobject\n",
      "                #   $98.5 = call $98.2($const98.3, n_train, func=$98.2, args=[Var($const98.3, <ipython-input-138-76c90ea42936> (61)), Var(n_train, <ipython-input-138-76c90ea42936> (44))], kws=(), vararg=None)  :: pyobject\n",
      "                #   del $const98.3\n",
      "                #   del $98.2\n",
      "                #   $98.6 = getiter(value=$98.5)  :: pyobject\n",
      "                #   del $98.5\n",
      "                #   $phi110.1 = $98.6  :: pyobject\n",
      "                #   del $98.6\n",
      "                #   jump 110\n",
      "                # label 110\n",
      "                #   $110.2 = iternext(value=$phi110.1)  :: pyobject\n",
      "                #   $110.3 = pair_first(value=$110.2)  :: pyobject\n",
      "                #   $110.4 = pair_second(value=$110.2)  :: pyobject\n",
      "                #   del $110.2\n",
      "                #   $phi112.1 = $110.3  :: pyobject\n",
      "                #   $phi180.1 = $110.3  :: pyobject\n",
      "                #   del $phi180.1\n",
      "                #   del $110.3\n",
      "                #   $phi180.2 = $phi110.1  :: pyobject\n",
      "                #   del $phi180.2\n",
      "                #   branch $110.4, 112, 180\n",
      "                # label 112\n",
      "                #   del $110.4\n",
      "                #   iTrain = $phi112.1  :: pyobject\n",
      "                #   del $phi112.1\n",
      "                #   del $112.12\n",
      "                #   del $112.17\n",
      "                #   del $112.22\n",
      "                #   del $112.23\n",
      "                #   del $112.18\n",
      "                #   del $112.24\n",
      "                #   del $112.13\n",
      "                #   del iTrain\n",
      "                #   del $112.29\n",
      "                #   del $112.30\n",
      "                #   del $112.25\n",
      "                #   del $112.8\n",
      "                #   del $112.31\n",
      "                #   del $112.5\n",
      "                #   del $112.32\n",
      "\n",
      "                for iTrain in np.arange(0, n_train):\n",
      "\n",
      "# --- LINE 62 --- \n",
      "\n",
      "\n",
      "\n",
      "                    # --- LINE 63 --- \n",
      "\n",
      "                    # calculate the derivative for the test points\n",
      "\n",
      "                    # --- LINE 64 --- \n",
      "                    #   $112.5 = build_tuple(items=[Var(iTest, <ipython-input-138-76c90ea42936> (58)), Var(idim, <ipython-input-138-76c90ea42936> (55))])  :: pyobject\n",
      "                    #   $112.8 = getitem(value=derivative, index=$112.5)  :: pyobject\n",
      "\n",
      "                    derivative[iTest, idim] += theta * weights[iTrain] *                                               (x_train[iTrain, idim] -\n",
      "\n",
      "                                               # --- LINE 65 --- \n",
      "                                               #   $112.12 = getitem(value=weights, index=iTrain)  :: pyobject\n",
      "                                               #   $112.13 = theta * $112.12  :: pyobject\n",
      "                                               #   $112.17 = build_tuple(items=[Var(iTrain, <ipython-input-138-76c90ea42936> (61)), Var(idim, <ipython-input-138-76c90ea42936> (55))])  :: pyobject\n",
      "                                               #   $112.18 = getitem(value=x_train, index=$112.17)  :: pyobject\n",
      "                                               #   $112.22 = build_tuple(items=[Var(iTest, <ipython-input-138-76c90ea42936> (58)), Var(idim, <ipython-input-138-76c90ea42936> (55))])  :: pyobject\n",
      "                                               #   $112.23 = getitem(value=x_function, index=$112.22)  :: pyobject\n",
      "                                               #   $112.24 = $112.18 - $112.23  :: pyobject\n",
      "                                               #   $112.25 = $112.13 * $112.24  :: pyobject\n",
      "\n",
      "                                               x_function[iTest, idim]) * \\\n",
      "\n",
      "                                              # --- LINE 66 --- \n",
      "                                              #   $112.29 = build_tuple(items=[Var(iTrain, <ipython-input-138-76c90ea42936> (61)), Var(iTest, <ipython-input-138-76c90ea42936> (58))])  :: pyobject\n",
      "                                              #   $112.30 = getitem(value=kernel_mat, index=$112.29)  :: pyobject\n",
      "                                              #   $112.31 = $112.25 * $112.30  :: pyobject\n",
      "                                              #   $112.32 = inplace_binop(fn=+=, immutable_fn=+, lhs=$112.8, rhs=$112.31, static_lhs=<object object at 0x11f34d240>, static_rhs=<object object at 0x11f34d240>)  :: pyobject\n",
      "                                              #   derivative[$112.5] = $112.32  :: pyobject\n",
      "                                              #   jump 110\n",
      "                                              # label 180\n",
      "                                              #   del iTest\n",
      "                                              #   del $phi112.1\n",
      "                                              #   del $phi110.1\n",
      "                                              #   del $110.4\n",
      "                                              #   jump 182\n",
      "                                              # label 182\n",
      "                                              #   jump 92\n",
      "                                              # label 184\n",
      "                                              #   del idim\n",
      "                                              #   del $phi94.1\n",
      "                                              #   del $phi92.1\n",
      "                                              #   del $92.4\n",
      "                                              #   jump 186\n",
      "                                              # label 186\n",
      "                                              #   jump 74\n",
      "                                              # label 188\n",
      "                                              #   del x_train\n",
      "                                              #   del x_function\n",
      "                                              #   del weights\n",
      "                                              #   del theta\n",
      "                                              #   del n_train\n",
      "                                              #   del n_test\n",
      "                                              #   del kernel_mat\n",
      "                                              #   del $phi76.1\n",
      "                                              #   del $phi74.1\n",
      "                                              #   del $74.4\n",
      "                                              #   jump 190\n",
      "\n",
      "                                              kernel_mat[iTrain, iTest]\n",
      "\n",
      "# --- LINE 67 --- \n",
      "\n",
      "\n",
      "\n",
      "    # --- LINE 68 --- \n",
      "\n",
      "    # 2nd derivative\n",
      "\n",
      "    # --- LINE 69 --- \n",
      "\n",
      "    elif n_derivative == 2:\n",
      "\n",
      "# --- LINE 70 --- \n",
      "\n",
      "\n",
      "\n",
      "        # --- LINE 71 --- \n",
      "\n",
      "        # loop through dimensions\n",
      "\n",
      "        # --- LINE 72 --- \n",
      "\n",
      "        for dim in np.arange(0, d_dimensions):\n",
      "\n",
      "# --- LINE 73 --- \n",
      "\n",
      "\n",
      "\n",
      "            # --- LINE 74 --- \n",
      "\n",
      "            # loop through the number of test points\n",
      "\n",
      "            # --- LINE 75 --- \n",
      "\n",
      "            for iTest in np.arange(0, n_test):\n",
      "\n",
      "# --- LINE 76 --- \n",
      "\n",
      "\n",
      "\n",
      "                # --- LINE 77 --- \n",
      "\n",
      "                # loop through the number of test points\n",
      "\n",
      "                # --- LINE 78 --- \n",
      "\n",
      "                for iTrain in np.arange(0, n_train):\n",
      "\n",
      "                    # --- LINE 79 --- \n",
      "\n",
      "                    derivative[iTest, dim] += weights[iTrain] *                                               (theta ** 2 *\n",
      "\n",
      "                                               # --- LINE 80 --- \n",
      "\n",
      "                                               (x_train[iTrain, dim] - x_function[iTest, dim]) ** 2\n",
      "\n",
      "                                               # --- LINE 81 --- \n",
      "\n",
      "                                               - theta) * \\\n",
      "\n",
      "                                              # --- LINE 82 --- \n",
      "\n",
      "                                              kernel_mat[iTrain, iTest]\n",
      "\n",
      "# --- LINE 83 --- \n",
      "\n",
      "\n",
      "\n",
      "    # --- LINE 84 --- \n",
      "\n",
      "    return derivative\n",
      "\n",
      "\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "rbf_derivative_numba.inspect_types()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numba w/ Jit:\n",
      "1.44 s ± 26.1 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "print('Numba w/ Jit:')\n",
    "jitted = %timeit -o rbf_derivative_numba(x_train, x_test, kernel_mat=kernel, weights=weights, gamma=gamma)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numba w/ Jit:\n",
      "1.62 s ± 58.8 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "fast_numba = jit()(rbf_derivative)\n",
    "\n",
    "print('Numba w/ Jit:')\n",
    "%timeit fast_numba(x_train, x_test, kernel_mat=kernel, weights=weights, gamma=gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'CPUDispatcher' object has no attribute '__defaults__'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-53-4bf638197df8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrbf_derivative_numba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdouble\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdouble\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdouble\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdouble\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdouble\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrbf_derivative_numba\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/numba/decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(func)\u001b[0m\n\u001b[1;32m    189\u001b[0m         disp = dispatcher(py_func=func, locals=locals,\n\u001b[1;32m    190\u001b[0m                           \u001b[0mtargetoptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtargetoptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m                           **dispatcher_args)\n\u001b[0m\u001b[1;32m    192\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m             \u001b[0mdisp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_caching\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/numba/dispatcher.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, py_func, locals, targetoptions, impl_kind)\u001b[0m\n\u001b[1;32m    470\u001b[0m         \u001b[0marg_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpysig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    471\u001b[0m         \u001b[0mcan_fallback\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtargetoptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'nopython'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 472\u001b[0;31m         \u001b[0m_DispatcherBase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg_count\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpy_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpysig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcan_fallback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    473\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m         \u001b[0mfunctools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpy_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/numba/dispatcher.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, arg_count, py_func, pysig, can_fallback)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[0margnames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpysig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m         \u001b[0mdefault_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpy_func\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__defaults__\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m         \u001b[0mdefargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mOmittedArg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdefault_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'CPUDispatcher' object has no attribute '__defaults__'"
     ]
    }
   ],
   "source": [
    "rbf_derivative_numba = jit(void(double[:], double[:,:], double[:,:], double[:,:], double[:]))(rbf_derivative_numba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "UntypedAttributeError",
     "evalue": "Failed at nopython (nopython frontend)\nUnknown attribute 'shape' of type Module(<module 'numpy' from '/Users/eman/anaconda3/lib/python3.6/site-packages/numpy/__init__.py'>)\nFile \"<ipython-input-26-6afc3b98ed16>\", line 42\n[1] During: typing of get attribute at <ipython-input-26-6afc3b98ed16> (42)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUntypedAttributeError\u001b[0m                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-96d43f8454b7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'timeit'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rbf_derivative_numba(x_train, x_test, kernel_mat=kernel, weights=weights, n_derivative=1, gamma=gamma)'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_line_magic\u001b[0;34m(self, magic_name, line, _stack_depth)\u001b[0m\n\u001b[1;32m   2093\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'local_ns'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_locals\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2094\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2095\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2096\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2097\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<decorator-gen-61>\u001b[0m in \u001b[0;36mtimeit\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtimeit\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1096\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1097\u001b[0m                 \u001b[0mnumber\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m                 \u001b[0mtime_number\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtimer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumber\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtime_number\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtimeit\u001b[0;34m(self, number)\u001b[0m\n\u001b[1;32m    158\u001b[0m         \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m             \u001b[0mtiming\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mgcold\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<magic-timeit>\u001b[0m in \u001b[0;36minner\u001b[0;34m(_it, _timer)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/numba/dispatcher.py\u001b[0m in \u001b[0;36m_compile_for_args\u001b[0;34m(self, *args, **kws)\u001b[0m\n\u001b[1;32m    328\u001b[0m                                 for i, err in failed_args))\n\u001b[1;32m    329\u001b[0m                 \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpatch_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 330\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    331\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minspect_llvm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/numba/dispatcher.py\u001b[0m in \u001b[0;36m_compile_for_args\u001b[0;34m(self, *args, **kws)\u001b[0m\n\u001b[1;32m    305\u001b[0m                 \u001b[0margtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtypeof_pyval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 307\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margtypes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTypingError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m             \u001b[0;31m# Intercept typing error that may be due to an argument\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/numba/dispatcher.py\u001b[0m in \u001b[0;36mcompile\u001b[0;34m(self, sig)\u001b[0m\n\u001b[1;32m    577\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cache_misses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 579\u001b[0;31m                 \u001b[0mcres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    580\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_overload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_overload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/numba/dispatcher.py\u001b[0m in \u001b[0;36mcompile\u001b[0;34m(self, args, return_type)\u001b[0m\n\u001b[1;32m     78\u001b[0m                                       \u001b[0mimpl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m                                       \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_type\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m                                       flags=flags, locals=self.locals)\n\u001b[0m\u001b[1;32m     81\u001b[0m         \u001b[0;31m# Check typing error if object mode is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtyping_error\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_pyobject\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/numba/compiler.py\u001b[0m in \u001b[0;36mcompile_extra\u001b[0;34m(typingctx, targetctx, func, args, return_type, flags, locals, library)\u001b[0m\n\u001b[1;32m    764\u001b[0m     pipeline = Pipeline(typingctx, targetctx, library,\n\u001b[1;32m    765\u001b[0m                         args, return_type, flags, locals)\n\u001b[0;32m--> 766\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile_extra\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    767\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    768\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/numba/compiler.py\u001b[0m in \u001b[0;36mcompile_extra\u001b[0;34m(self, func)\u001b[0m\n\u001b[1;32m    360\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlifted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlifted_from\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 362\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compile_bytecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcompile_ir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc_ir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlifted\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlifted_from\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/numba/compiler.py\u001b[0m in \u001b[0;36m_compile_bytecode\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    723\u001b[0m         \"\"\"\n\u001b[1;32m    724\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc_ir\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 725\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compile_core\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    726\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_compile_ir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/numba/compiler.py\u001b[0m in \u001b[0;36m_compile_core\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    710\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    711\u001b[0m         \u001b[0mpm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 712\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    713\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    714\u001b[0m             \u001b[0;31m# Early pipeline completion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/numba/compiler.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, status)\u001b[0m\n\u001b[1;32m    246\u001b[0m                     \u001b[0;31m# No more fallback pipelines?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mis_final_pipeline\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 248\u001b[0;31m                         \u001b[0;32mraise\u001b[0m \u001b[0mpatched_exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    249\u001b[0m                     \u001b[0;31m# Go to next fallback pipeline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/numba/compiler.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, status)\u001b[0m\n\u001b[1;32m    238\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m                     \u001b[0mevent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstage_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 240\u001b[0;31m                     \u001b[0mstage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    241\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0m_EarlyPipelineCompletion\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/numba/compiler.py\u001b[0m in \u001b[0;36mstage_nopython_frontend\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    452\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_type\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m                 self.locals)\n\u001b[0m\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m         with self.fallback_context('Function \"%s\" has invalid return type'\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/numba/compiler.py\u001b[0m in \u001b[0;36mtype_inference_stage\u001b[0;34m(typingctx, interp, args, return_type, locals)\u001b[0m\n\u001b[1;32m    866\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    867\u001b[0m         \u001b[0minfer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_constraint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 868\u001b[0;31m         \u001b[0minfer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpropagate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    869\u001b[0m         \u001b[0mtypemap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrestype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcalltypes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minfer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/numba/typeinfer.py\u001b[0m in \u001b[0;36mpropagate\u001b[0;34m(self, raise_errors)\u001b[0m\n\u001b[1;32m    842\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    843\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mraise_errors\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 844\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    845\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    846\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/numba/typeinfer.py\u001b[0m in \u001b[0;36mpropagate\u001b[0;34m(self, typeinfer)\u001b[0m\n\u001b[1;32m    135\u001b[0m                                                    lineno=loc.line):\n\u001b[1;32m    136\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m                     \u001b[0mconstraint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtypeinfer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mTypingError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m                     \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/numba/typeinfer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, typeinfer)\u001b[0m\n\u001b[1;32m    517\u001b[0m                 \u001b[0mattrty\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtypeinfer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresolve_getattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mattrty\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 519\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mUntypedAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    520\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m                     \u001b[0;32massert\u001b[0m \u001b[0mattrty\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_precise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUntypedAttributeError\u001b[0m: Failed at nopython (nopython frontend)\nUnknown attribute 'shape' of type Module(<module 'numpy' from '/Users/eman/anaconda3/lib/python3.6/site-packages/numpy/__init__.py'>)\nFile \"<ipython-input-26-6afc3b98ed16>\", line 42\n[1] During: typing of get attribute at <ipython-input-26-6afc3b98ed16> (42)"
     ]
    }
   ],
   "source": [
    "%timeit rbf_derivative_numba(x_train, x_test, kernel_mat=kernel, weights=weights, n_derivative=1, gamma=gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.9 ms ± 176 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(700, 1) int64\n",
      "(300, 1) int64\n",
      "(700, 700) float64\n",
      "(700,) float64\n",
      "() float64 float64\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape, x_train.dtype)\n",
    "print(x_test.shape, x_test.dtype)\n",
    "print(kernel.shape, kernel.dtype)\n",
    "print(weights.squeeze().shape, weights.squeeze().dtype)\n",
    "print(gamma.shape, gamma.dtype, gamma.astype(np.float).dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
